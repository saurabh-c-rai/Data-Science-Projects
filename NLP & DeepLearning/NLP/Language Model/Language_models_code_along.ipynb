{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YInsm7I_lnkL"
   },
   "source": [
    "# Find the bigram probabilities of the sentence tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "[nltk_data] Downloading package brown to\n[nltk_data]     /Users/raisaurabh04/nltk_data...\n[nltk_data]   Package brown is already up-to-date!\n"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corpus\n",
    "words = brown.words()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['the',\n 'fulton',\n 'county',\n 'grand',\n 'jury',\n 'said',\n 'friday',\n 'an',\n 'investigation',\n 'of']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=[w.lower() for w in words]\n",
    "\n",
    "words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "FreqDist({'the': 69971, ',': 58334, '.': 49346, 'of': 36412, 'and': 28853, 'to': 26158, 'a': 23195, 'in': 21337, 'that': 10594, 'is': 10109, ...})"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unigram frequency \n",
    "uni_freq = nltk.FreqDist(w.lower() for w in words)\n",
    "uni_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1161192"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of corpus\n",
    "total_words = len(words)\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Frequency of tokens of the sample sentence: 1161192\n"
    }
   ],
   "source": [
    "print('Frequency of tokens of the sample sentence:',total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentence \n",
    "test_sentence_tokens=['this','is','a','sunny','day','.','however','i','am','not','feeling','well','lots','of','cold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "Fdk5m696LuZu",
    "outputId": "6aabf1f0-47bd-468d-8a2b-5624d7c507f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of \"this\" is 5145\n",
      "Frequency of \"is\" is 10109\n",
      "Frequency of \"a\" is 23195\n",
      "Frequency of \"sunny\" is 13\n",
      "Frequency of \"day\" is 687\n",
      "Frequency of \".\" is 49346\n",
      "Frequency of \"however\" is 552\n",
      "Frequency of \"i\" is 5164\n",
      "Frequency of \"am\" is 237\n",
      "Frequency of \"not\" is 4610\n",
      "Frequency of \"feeling\" is 172\n",
      "Frequency of \"well\" is 897\n",
      "Frequency of \"lots\" is 42\n",
      "Frequency of \"of\" is 36412\n",
      "Frequency of \"cold\" is 171\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in test_sentence_tokens:\n",
    "    print(f'Frequency of \\\"{word}\\\" is {uni_freq[word]}')\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bigrams\n",
    "\n",
    "bigram_words = []\n",
    "previous = 'EMPTY'\n",
    "sentences = 0\n",
    "for word in words:\n",
    "    if previous in ['EMPTY','.','?','!']:\n",
    "        ## insert word_boundaries at beginning of Brown,\n",
    "        bigram_words.append('*start_end*')\n",
    "    else:\n",
    "        bigram_words.append(previous)\n",
    "        \n",
    "    previous = word\n",
    "\n",
    "bigram_words.append('*start_end*') ## assume one additional *start_end* at the end of Brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['*start_end*',\n 'the',\n 'fulton',\n 'county',\n 'grand',\n 'jury',\n 'said',\n 'friday',\n 'an',\n 'investigation',\n 'of',\n \"atlanta's\",\n 'recent',\n 'primary',\n 'election',\n 'produced',\n '``',\n 'no',\n 'evidence',\n \"''\"]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_words[ : 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Calculating bigram probalities for sentence, including bigrams with sentence boundaries, i.e., *start_end*\n"
    }
   ],
   "source": [
    "updated_uni_freq  = nltk.FreqDist(w.lower() for w in bigram_words)\n",
    "\n",
    "\n",
    "print('Calculating bigram probalities for sentence, including bigrams with sentence boundaries, i.e., *start_end*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['*start_end*',\n 'the',\n 'fulton',\n 'county',\n 'grand',\n 'jury',\n 'said',\n 'friday',\n 'an',\n 'investigation',\n 'of',\n \"atlanta's\",\n 'recent',\n 'primary',\n 'election',\n 'produced',\n '``',\n 'no',\n 'evidence',\n \"''\",\n 'that',\n 'any',\n 'irregularities',\n 'took',\n 'place',\n '*start_end*',\n 'the',\n 'jury',\n 'further',\n 'said',\n 'in',\n 'term-end',\n 'presentments',\n 'that',\n 'the',\n 'city',\n 'executive',\n 'committee',\n ',',\n 'which',\n 'had',\n 'over-all',\n 'charge',\n 'of',\n 'the',\n 'election',\n ',',\n '``',\n 'deserves',\n 'the',\n 'praise',\n 'and',\n 'thanks',\n 'of',\n 'the',\n 'city',\n 'of',\n 'atlanta',\n \"''\",\n 'for',\n 'the',\n 'manner',\n 'in',\n 'which',\n 'the',\n 'election',\n 'was',\n 'conducted',\n '*start_end*',\n 'the',\n 'september-october',\n 'term',\n 'jury',\n 'had',\n 'been',\n 'charged',\n 'by',\n 'fulton',\n 'superior',\n 'court',\n 'judge',\n 'durwood',\n 'pye',\n 'to',\n 'investigate',\n 'reports',\n 'of',\n 'possible',\n '``',\n 'irregularities',\n \"''\",\n 'in',\n 'the',\n 'hard-fought',\n 'primary',\n 'which',\n 'was',\n 'won',\n 'by',\n 'mayor-nominate',\n 'ivan',\n 'allen',\n 'jr.',\n '*start_end*',\n '``',\n 'only',\n 'a',\n 'relative',\n 'handful',\n 'of',\n 'such',\n 'reports',\n 'was',\n 'received',\n \"''\",\n ',',\n 'the',\n 'jury',\n 'said',\n ',',\n '``',\n 'considering',\n 'the',\n 'widespread',\n 'interest',\n 'in',\n 'the',\n 'election',\n ',',\n 'the',\n 'number',\n 'of',\n 'voters',\n 'and',\n 'the',\n 'size',\n 'of',\n 'this',\n 'city',\n \"''\",\n '*start_end*',\n 'the',\n 'jury',\n 'said',\n 'it',\n 'did',\n 'find',\n 'that',\n 'many',\n 'of',\n \"georgia's\",\n 'registration',\n 'and',\n 'election',\n 'laws',\n '``',\n 'are',\n 'outmoded',\n 'or',\n 'inadequate',\n 'and',\n 'often',\n 'ambiguous',\n \"''\",\n '*start_end*',\n 'it',\n 'recommended',\n 'that',\n 'fulton',\n 'legislators',\n 'act',\n '``',\n 'to',\n 'have',\n 'these',\n 'laws',\n 'studied',\n 'and',\n 'revised',\n 'to',\n 'the',\n 'end',\n 'of',\n 'modernizing',\n 'and',\n 'improving',\n 'them',\n \"''\",\n '*start_end*',\n 'the',\n 'grand',\n 'jury',\n 'commented',\n 'on',\n 'a',\n 'number',\n 'of',\n 'other',\n 'topics',\n ',',\n 'among',\n 'them',\n 'the',\n 'atlanta',\n 'and',\n 'fulton',\n 'county',\n 'purchasing',\n 'departments',\n 'which',\n 'it',\n 'said',\n '``',\n 'are',\n 'well',\n 'operated',\n 'and',\n 'follow',\n 'generally',\n 'accepted',\n 'practices',\n 'which',\n 'inure',\n 'to',\n 'the',\n 'best',\n 'interest',\n 'of',\n 'both',\n 'governments',\n \"''\",\n '*start_end*',\n 'merger',\n 'proposed',\n 'however',\n ',',\n 'the',\n 'jury',\n 'said',\n 'it',\n 'believes',\n '``',\n 'these',\n 'two',\n 'offices',\n 'should',\n 'be',\n 'combined',\n 'to',\n 'achieve',\n 'greater',\n 'efficiency',\n 'and',\n 'reduce',\n 'the',\n 'cost',\n 'of',\n 'administration',\n \"''\",\n '*start_end*',\n 'the',\n 'city',\n 'purchasing',\n 'department',\n ',',\n 'the',\n 'jury',\n 'said',\n ',',\n '``',\n 'is',\n 'lacking',\n 'in',\n 'experienced',\n 'clerical',\n 'personnel',\n 'as',\n 'a',\n 'result',\n 'of',\n 'city',\n 'personnel',\n 'policies',\n \"''\",\n '*start_end*',\n 'it',\n 'urged',\n 'that',\n 'the',\n 'city',\n '``',\n 'take',\n 'steps',\n 'to',\n 'remedy',\n \"''\",\n 'this',\n 'problem',\n '*start_end*',\n 'implementation',\n 'of',\n \"georgia's\",\n 'automobile',\n 'title',\n 'law',\n 'was',\n 'also',\n 'recommended',\n 'by',\n 'the',\n 'outgoing',\n 'jury',\n '*start_end*',\n 'it',\n 'urged',\n 'that',\n 'the',\n 'next',\n 'legislature',\n '``',\n 'provide',\n 'enabling',\n 'funds',\n 'and',\n 're-set',\n 'the',\n 'effective',\n 'date',\n 'so',\n 'that',\n 'an',\n 'orderly',\n 'implementation',\n 'of',\n 'the',\n 'law',\n 'may',\n 'be',\n 'effected',\n \"''\",\n '*start_end*',\n 'the',\n 'grand',\n 'jury',\n 'took',\n 'a',\n 'swipe',\n 'at',\n 'the',\n 'state',\n 'welfare',\n \"department's\",\n 'handling',\n 'of',\n 'federal',\n 'funds',\n 'granted',\n 'for',\n 'child',\n 'welfare',\n 'services',\n 'in',\n 'foster',\n 'homes',\n '*start_end*',\n '``',\n 'this',\n 'is',\n 'one',\n 'of',\n 'the',\n 'major',\n 'items',\n 'in',\n 'the',\n 'fulton',\n 'county',\n 'general',\n 'assistance',\n 'program',\n \"''\",\n ',',\n 'the',\n 'jury',\n 'said',\n ',',\n 'but',\n 'the',\n 'state',\n 'welfare',\n 'department',\n '``',\n 'has',\n 'seen',\n 'fit',\n 'to',\n 'distribute',\n 'these',\n 'funds',\n 'through',\n 'the',\n 'welfare',\n 'departments',\n 'of',\n 'all',\n 'the',\n 'counties',\n 'in',\n 'the',\n 'state',\n 'with',\n 'the',\n 'exception',\n 'of',\n 'fulton',\n 'county',\n ',',\n 'which',\n 'receives',\n 'none',\n 'of',\n 'this',\n 'money',\n '*start_end*',\n 'the',\n 'jurors',\n 'said',\n 'they',\n 'realize',\n '``',\n 'a',\n 'proportionate',\n 'distribution',\n 'of',\n 'these',\n 'funds',\n 'might',\n 'disable',\n 'this',\n 'program',\n 'in',\n 'our',\n 'less',\n 'populous',\n 'counties',\n \"''\",\n '*start_end*',\n 'nevertheless',\n ',',\n '``',\n 'we',\n 'feel',\n 'that',\n 'in',\n 'the',\n 'future',\n 'fulton',\n 'county',\n 'should',\n 'receive',\n 'some',\n 'portion',\n 'of',\n 'these',\n 'available',\n 'funds',\n \"''\",\n ',',\n 'the',\n 'jurors',\n 'said',\n '*start_end*',\n '``',\n 'failure',\n 'to',\n 'do',\n 'this',\n 'will',\n 'continue',\n 'to',\n 'place',\n 'a',\n 'disproportionate',\n 'burden',\n \"''\",\n 'on',\n 'fulton',\n 'taxpayers',\n '*start_end*',\n 'the',\n 'jury',\n 'also',\n 'commented',\n 'on',\n 'the',\n 'fulton',\n \"ordinary's\",\n 'court',\n 'which',\n 'has',\n 'been',\n 'under',\n 'fire',\n 'for',\n 'its',\n 'practices',\n 'in',\n 'the',\n 'appointment',\n 'of',\n 'appraisers',\n ',',\n 'guardians',\n 'and',\n 'administrators',\n 'and',\n 'the',\n 'awarding',\n 'of',\n 'fees',\n 'and',\n 'compensation',\n '*start_end*',\n 'wards',\n 'protected',\n 'the',\n 'jury',\n 'said',\n 'it',\n 'found',\n 'the',\n 'court',\n '``',\n 'has',\n 'incorporated',\n 'into',\n 'its',\n 'operating',\n 'procedures',\n 'the',\n 'recommendations',\n \"''\",\n 'of',\n 'two',\n 'previous',\n 'grand',\n 'juries',\n ',',\n 'the',\n 'atlanta',\n 'bar',\n 'association',\n 'and',\n 'an',\n 'interim',\n 'citizens',\n 'committee',\n '*start_end*',\n '``',\n 'these',\n 'actions',\n 'should',\n 'serve',\n 'to',\n 'protect',\n 'in',\n 'fact',\n 'and',\n 'in',\n 'effect',\n 'the',\n \"court's\",\n 'wards',\n 'from',\n 'undue',\n 'costs',\n 'and',\n 'its',\n 'appointed',\n 'and',\n 'elected',\n 'servants',\n 'from',\n 'unmeritorious',\n 'criticisms',\n \"''\",\n ',',\n 'the',\n 'jury',\n 'said',\n '*start_end*',\n 'regarding',\n \"atlanta's\",\n 'new',\n 'multi-million-dollar',\n 'airport',\n ',',\n 'the',\n 'jury',\n 'recommended',\n '``',\n 'that',\n 'when',\n 'the',\n 'new',\n 'management',\n 'takes',\n 'charge',\n 'jan.',\n '1',\n 'the',\n 'airport',\n 'be',\n 'operated',\n 'in',\n 'a',\n 'manner',\n 'that',\n 'will',\n 'eliminate',\n 'political',\n 'influences',\n \"''\",\n '*start_end*',\n 'the',\n 'jury',\n 'did',\n 'not',\n 'elaborate',\n ',',\n 'but',\n 'it',\n 'added',\n 'that',\n '``',\n 'there',\n 'should',\n 'be',\n 'periodic',\n 'surveillance',\n 'of',\n 'the',\n 'pricing',\n 'practices',\n 'of',\n 'the',\n 'concessionaires',\n 'for',\n 'the',\n 'purpose',\n 'of',\n 'keeping',\n 'the',\n 'prices',\n 'reasonable',\n \"''\",\n '*start_end*',\n 'ask',\n 'jail',\n 'deputies',\n 'on',\n 'other',\n 'matters',\n ',',\n 'the',\n 'jury',\n 'recommended',\n 'that',\n ':',\n '(',\n '1',\n ')',\n 'four',\n 'additional',\n 'deputies',\n 'be',\n 'employed',\n 'at',\n 'the',\n 'fulton',\n 'county',\n 'jail',\n 'and',\n '``',\n 'a',\n 'doctor',\n ',',\n 'medical',\n 'intern',\n 'or',\n 'extern',\n 'be',\n 'employed',\n 'for',\n 'night',\n 'and',\n 'weekend',\n 'duty',\n 'at',\n 'the',\n 'jail',\n \"''\",\n '*start_end*',\n '(',\n '2',\n ')',\n 'fulton',\n 'legislators',\n '``',\n 'work',\n 'with',\n 'city',\n 'officials',\n 'to',\n 'pass',\n 'enabling',\n 'legislation',\n 'that',\n 'will',\n 'permit',\n 'the',\n 'establishment',\n 'of',\n 'a',\n 'fair',\n 'and',\n 'equitable',\n \"''\",\n 'pension',\n 'plan',\n 'for',\n 'city',\n 'employes',\n '*start_end*',\n 'the',\n 'jury',\n 'praised',\n 'the',\n 'administration',\n 'and',\n 'operation',\n 'of',\n 'the',\n 'atlanta',\n 'police',\n 'department',\n ',',\n 'the',\n 'fulton',\n 'tax',\n \"commissioner's\",\n 'office',\n ',',\n 'the',\n 'bellwood',\n 'and',\n 'alpharetta',\n 'prison',\n 'farms',\n ',',\n 'grady',\n 'hospital',\n 'and',\n 'the',\n 'fulton',\n 'health',\n 'department',\n '*start_end*',\n 'mayor',\n 'william',\n 'b.',\n 'hartsfield',\n 'filed',\n 'suit',\n 'for',\n 'divorce',\n 'from',\n 'his',\n 'wife',\n ',',\n 'pearl',\n 'williams',\n 'hartsfield',\n ',',\n 'in',\n 'fulton',\n 'superior',\n 'court',\n 'friday',\n '*start_end*',\n 'his',\n 'petition',\n 'charged',\n 'mental',\n 'cruelty',\n '*start_end*',\n 'the',\n 'couple',\n 'was',\n 'married',\n 'aug.',\n '2',\n ',',\n '1913',\n '*start_end*',\n 'they',\n 'have',\n 'a',\n 'son',\n ',',\n 'william',\n 'berry',\n 'jr.',\n ',',\n 'and',\n 'a',\n 'daughter',\n ',',\n 'mrs.',\n 'j.',\n 'm.',\n 'cheshire',\n 'of',\n 'griffin',\n '*start_end*',\n 'attorneys',\n 'for',\n 'the',\n 'mayor',\n 'said',\n 'that',\n 'an',\n 'amicable',\n 'property',\n 'settlement',\n 'has',\n 'been',\n 'agreed',\n 'upon',\n '*start_end*',\n 'the',\n 'petition',\n 'listed',\n 'the',\n \"mayor's\",\n 'occupation',\n 'as',\n '``',\n 'attorney',\n \"''\",\n 'and',\n 'his',\n 'age',\n 'as',\n '71',\n '*start_end*',\n 'it',\n 'listed',\n 'his',\n \"wife's\",\n 'age',\n 'as',\n '74',\n 'and',\n 'place',\n 'of',\n 'birth',\n 'as',\n 'opelika',\n ',',\n 'ala.',\n '*start_end*',\n 'the',\n 'petition',\n 'said',\n 'that',\n 'the',\n 'couple',\n 'has',\n 'not',\n 'lived',\n 'together',\n 'as',\n 'man',\n 'and',\n 'wife',\n 'for',\n 'more',\n 'than',\n 'a',\n 'year',\n '*start_end*',\n 'the',\n 'hartsfield',\n 'home',\n 'is',\n 'at',\n '637',\n 'e.',\n 'pelham',\n 'rd.',\n 'aj',\n '*start_end*',\n 'henry',\n 'l.',\n 'bowden',\n 'was',\n 'listed',\n 'on',\n 'the',\n 'petition',\n 'as',\n 'the',\n \"mayor's\",\n 'attorney',\n '*start_end*',\n 'hartsfield',\n 'has',\n 'been',\n 'mayor',\n 'of',\n 'atlanta',\n ',',\n 'with',\n 'exception',\n 'of',\n 'one',\n 'brief',\n 'interlude',\n ',',\n 'since',\n '1937',\n '*start_end*',\n 'his',\n 'political',\n 'career',\n 'goes',\n 'back',\n 'to',\n 'his',\n 'election',\n 'to',\n 'city',\n 'council',\n 'in',\n '1923',\n '*start_end*',\n 'the',\n \"mayor's\",\n 'present',\n 'term',\n 'of',\n 'office',\n 'expires',\n 'jan.',\n '1',\n '*start_end*',\n 'he',\n 'will',\n 'be',\n 'succeeded',\n 'by',\n 'ivan',\n 'allen',\n 'jr.',\n ',',\n 'who',\n 'became',\n 'a',\n 'candidate',\n 'in',\n 'the',\n 'sept.',\n '13',\n 'primary',\n 'after',\n 'mayor',\n 'hartsfield',\n 'announced',\n 'that',\n 'he',\n 'would',\n 'not',\n 'run',\n 'for',\n 'reelection',\n '*start_end*',\n 'georgia',\n 'republicans',\n 'are',\n 'getting',\n 'strong',\n 'encouragement',\n 'to',\n 'enter',\n 'a',\n 'candidate',\n 'in',\n 'the',\n '1962',\n ...]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "69971"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(bigram_words)\n",
    "freq['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "FreqDist({'the': 69971, ',': 58334, '*start_end*': 55636, 'of': 36412, 'and': 28853, 'to': 26158, 'a': 23195, 'in': 21337, 'that': 10594, 'is': 10109, ...})"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_uni_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "eturn to public notice ; ; and it is not unlikely that , even as the great Bach lay dormant for so many years , so has the erudite , ingenious SalFininistas passed through his `` purgatory '' of neglect . But now , under the guidance of the contemporary composer Marc Schlek , Jr. , a major revival is under way . As he leads the Neurenschatz Skolkau Orchestra , Schlek gives a tremendously inspired performance of both the Baslot and Rattzhenfuut concertos , including the controversial Tschilwyk cadenza , which was included at the conductor's insistence . A major portion of the credit should also go to flautist Haumd for his rendering of the almost impossible `` Indianapolis '' movement in the Baslot . Not only was Haumd's intonation and phrasing without flaw , but he seemed to take every tonal eccentricity in stride . For example , to move ( as the score requires ) from the lowest F-major register up to a barely audible N minor in four seconds , not skipping , at the same time , even one of the 407 fingerings , seems a feat too absurd to consider , and it is to the flautist's credit that he remained silent throughout the passage . We would have preferred , however , to have had the rest of the orchestra refrain from laughing at this and other spots on the recording , since it mars an otherwise sober , if not lofty , performance . As Broadway itself becomes increasingly weighted down by trite , heavy-handed , commercially successful musicals and inspirational problem dramas , the American theatre is going through an inexorable renaissance in that nebulous area known as `` off-Broadway '' . For the last two years , this frontier of the arts has produced a number of so-called `` non-dramas '' which have left indelible , bittersweet impressions on the psyche of this veteran theatregoer . The latest and , significantly , greatest fruit of this theatrical vine is The , an adaptation of Basho's classic frog-haiku by Roger Entwhistle , a former University of Maryland chemistry instructor . Although the play does show a certain structural amateurishness ( there are eleven acts varying in length from twenty-five seconds to an hour and a half ) , the statement it makes concerning the ceaseless yearning and searching of youth is profound and worthy of our attention . The action centers about a group of outspoken and offbeat students sitting around a table in a cafeteria and their collective and ultimately fruitless search for a cup of hot coffee . They are relentlessly rebuffed on all sides by a waitress , the police , and an intruding government tutor . The innocence that they tried to conceal at the beginning is clearly destroyed forever when one of them , asking for a piece of lemon-meringue pie , gets a plate of English muffins instead . Leaving the theatre after the performance , I had a flash of intuition that life , after all ( as Rilke said ) , is just a search for the nonexistent cup of hot coffee , and that this unpretentious , moving , clever , bitter slice of life was the greatest thing to happen to the American theatre since Brooks Atkinson retired . Aging but still precocious , French feline enfant terrible Francoisette Lagoon has succeeded in shocking jaded old Paris again , this time with a sexy ballet scenario called The Lascivious Interlude , the story of a nymphomaniac trip-hammer operator who falls hopelessly in love with a middle-aged steam shovel . A biting , pithy parable of the all-pervading hollowness of modern life , the piece has been set by Mlle Lagoon to a sumptuous score ( a single motif played over and over by four thousand French horns ) by existentialist hot-shot Jean-Paul Sartre . Petite , lovely Yvette Chadroe plays the nymphomaniac engagingly . Ever since Bambi , and , more recently , Born Free , there have been a lot of books about animals , but few compare with Max Fink's wry , understated , charming , and immensely readable My Friend , the Quizzical Salamander . Done in the modern style of a `` confession '' , Fink tells in exquisite detail how he came to know , and , more important , love his mother's pet salamander , Alicia . It is not an entirely happy book , as Mrs. Fink soon becomes jealous of Alicia and , in retaliation , refuses to continue to scrape the algae off her glass . Max , in a fit of despair , takes Alicia and runs off for two marvelous weeks in Burbank ( Fink calls it `` the most wonderful and lovely fourteen days in my whole life '' ) , at the end of which Alicia tragically contracts Parkinson's disease and dies . This brief resume hardly does the book justice , but I heartily recommend it to all those who are engages with the major problems of our time . Opera in the Grand Tradition , along with mah-jongg , seems to be staging a well-deserved comeback . In this country , the two guiding lights are , without doubt , Felix Fing and Anna Pulova . Fing , a lean , chiseled , impeccable gentleman of the old school who was once mistaken on the street for Sir Cedric Hardwicke , is responsible for the rediscovery of Verdi's earliest , most raucous opera , Nabisco , a sumptuous bout-de-souffle with a haunting leitmotiv that struck me as being highly reminiscent of the Mudugno version of `` Volare '' . Miss Pulova has a voice that Maria Callas once described as `` like chipping teeth with a screw driver '' , and her round , opalescent face becomes fascinatingly reflective of the emotions demanded by the role of Rosalie . The Champs Elysees is literally littered this summer with the prostrate bodies of France's beat-up beatnik jeunes filles . Cause of all this commotion : squat , pug-nosed , balding , hopelessly ugly Jean-Pierre Bravado , a Bogartian figure , who plays a sadistic , amoral , philosophic Tasti-Freeze salesman in old New-Waver Fredrico de Mille Rossilini's endlessly provocative film , A Sour Sponge . Bravado has been alternately described as `` a symbol of the new grandeur of France and myself '' ( De Gaulle ) and `` a decadent , disgusting slob '' ! ! ( Norman Mailer ) , but no one can deny that the screen crackles with electricity whenever he is on it . Soaring to stardom along with him , Margo Felicity Brighetti , a luscious and curvaceously beguiling Italian starlet , turns in a creditable performance as an airplane mechanic . The battle of the drib-drool continues , but most of New York's knowing sophisticates of Abstract Expressionism are stamping their feet impatiently in expectation of V ( for Vindication ) Day , September first , when Augustus Quasimodo's first one-man show opens at the Guggenheim . We have heard that after seeing Mr. Quasimodo's work it will be virtually impossible to deny the artistic validity and importance of the whole abstract movement . And it is thought by many who think about such things that Quasimodo is the logical culmination of a school that started with Monet , progressed through Kandinsky and the cubist Picasso , and blossomed just recently in Pollock and De Kooning . Quasimodo defines his own art as `` the search for what is not there '' . `` I paint the nothing '' , he said once to Franz Kline and myself , `` the nothing that is behind the something , the inexpressible , unpaintable ' tick ' in the unconscious , the ' spirit ' of the moment resting forever , suspended like a huge balloon , in non-time '' . It is his relentlessness and unwaivering adherence to this revolutionary artistic philosophy that has enabled him to paint such pictures as `` The Invasion of Cuba '' . In this work , his use of non-color is startling and skillful . The sweep of space , the delicate counterbalance of the white masses , the over-all completeness and unity , the originality and imagination , all entitle it to be called an authentic masterpiece . I asked Quasimodo recently how he accomplished this , and he replied that he had painted his model `` a beautiful shade of red and then had her breathe on the canvas '' , which was his typical tongue-in-cheek way of chiding me for my lack of sensitivity . Dear Sirs : Let me begin by clearing up any possible misconception in your minds , wherever you are . The collective by which I address you in the title above is neither patronizing nor jocose but an exact industrial term in use among professional thieves . It is , I am reliably given to understand , the technical argot for those who engage in your particular branch of the boost ; ; i.e. , burglars who rob while the tenants are absent , in contrast to hot-slough prowlers , those who work while the occupants are home . Since the latter obviously require an audacity you do not possess , you may perhaps suppose that I am taunting you as socially inferior . Far from it ; ; I merely draw an etymological distinction , hoping that specialists and busy people like you will welcome such precision in a layman . Above all , disabuse yourselves of any thought that I propose to vent moral indignation at your rifling my residence , to whimper over the loss of a few objets d'art , or to shame you into rectitude . My object , rather , is to alert you to an aspect or two of the affair that could have the gravest implications for you , far beyond the legal sanctions society might inflict . You have unwittingly set in motion forces so malign , so vindictive , that it would be downright inhumane of me not to warn you about them . Quite candidly , fellows , I wouldn't be in your shoes for all the rice in China . As you've doubtless forgotten the circumstances in the press of more recent depredations , permit me to recapitulate them briefly . Sometime on Saturday evening , August 22nd , while my family and I were dining at the Hostaria dell' Orso , in Rome , you jimmied a window of our home in Bucks County , Pennsylvania , and let yourselves into the premises . Hastening to the attic , the temperature of which was easily hotter than the Gold Coast , you proceeded to mask the windows with a fancy wool coverlet , some khaki pants , and the like , and to ransack the innumerable boxes and barrels stored there . What you were looking for ( unless you make a hobby of collecting old tennis rackets and fly screens ) eludes me , but to judge from phonograph records scattered about a fumed-oak Victrola . You danced two tangos and a paso doble , which must have been fairly enervating in that milieu . You then descended one story , glommed a television set from the music room -- the only constructive feature of your visit , by the way -- and , returning to the ground floor , entered the master bedroom . From the curio cabinet on its south wall and the bureaus beneath , you abstracted seventeen ivory , metal , wood , and stone sculptures of Oriental and African origin , two snuffboxes , and a jade-handled magnifying glass . Rummaging through a stack of drawers nearby , you unearthed an antique French chess set in ivory and sandalwood , which , along with two box Kodaks , you added to your haul . Then , having wrapped the lot in an afghan my dog customarily slept on , you lammed out the front door , considerately leaving it open for neighbors to discover . So much for the tiresome facts , as familiar to you , I'm sure , as to the constables and state troopers who followed in your wake . The foregoing , aided by several clues I'll withhold to keep you on your toes , will pursue you with a tenacity worthy of Inspector Javert , but before they close in , gird yourselves , I repeat , for a vengeance infinitely more pitiless . Fourteen of the sculptures you took possess properties of a most curious and terrifying nature , as you will observe when your limbs begin to wither and your hair falls out in patches . In time , these minor manifestations will multiply and effloresce , riddling you with frambesia , the king's evil , sheep rot , and clonic spasm , until your very existence becomes a burden and you cry out for release . All this , though , is simply a prelude , a curtain-raiser , for what ensues , and I doubt whether any Occidental could accurately forecast it . If , however , it would help to intensify your anguish , I can delimit the powers of a few of the divinities you've affronted and describe the punishment they meted out in one analogous instance . Hold on tight . First of all , the six figures of the Buddha you heisted -- four Siamese heads , a black obsidian statuette in the earth-touching position , and a large brass figure of the Dying Buddha on a teakwood base . Now , you probably share the widespread Western belief that the Lord Buddha is the most compassionate of the gods , much more so than Jehovah and Allah and the rest . 'fess up -- don't you ? ? Well , ordinarily he is , except ( as the Wheel of the Law specifies ) toward impious folk who steal , disturb , or maltreat the Presence . Very peculiar retribution indeed seems to overtake such jokers . Eight or ten years ago , a couple of French hoods stole a priceless Khmer head from the Musee Guimet , in Paris , and a week later crawled into the Salpetriere with unmistakable symptoms of leprosy . Hell's own amount of chaulmoogra oil did nothing to alleviate their torment ; ; they expired amid indescribable fantods , imploring the Blessed One to forgive their desecration . Any reputable French interne can supply you with a dozen similar instances , and I'll presently recount a case out of my own personal experience , but , for the moment , let's resume our catalogue . Whether the pair of Sudanese ivory carvings you lifted really possess the juju to turn your livers to lead , as a dealer in Khartoum assured me , I am not competent to say . Likewise the ivory Chinese female figure known as a `` doctor lady '' ( provenance Honan ) ; ; a friend of mine removing her from the curio cabinet for inspection was felled as if by a hammer , but he had previously drunk a quantity of applejack . The three Indian brass deities , though -- Ganessa , Siva , and Krishna -- are an altogether different cup of tea . They hail from Travancore , a state in the subcontinent where Kali , the goddess of death , is worshiped . Have you ever heard of Thuggee ? ? Nuf sed . But it is the wooden sculpture from Bali , the one representing two men with their heads bent backward and their bodies interlaced by a fish , that I particularly call to your attention . Oddly enough , this is an amulet against housebreakers , presented to the mem and me by a local rajah in 1949 . Inscribed around its base is a charm in Balinese , a dialect I take it you don't comprehend . Neither do I , but the Tjokorda Agoeng was good enough to translate , and I'll do as much for you . Whosoever violates our rooftree , the legend states , can expect maximal sorrow . The teeth will rain from his mouth like pebbles , his wife will make him cocu with fishmongers , and a trolley car will grow in his stomach . Furthermore -- and this , to me , strikes an especially warming note -- it shall avail the vandals naught to throw away or dispose of their loot . The cycle of disaster starts the moment they touch any belonging of ours , and dogs them unto the forty-fifth generation . Sort of remorseless , isn't it ? ? Still , there it is . Now , you no doubt regard the preceding as pap ; ; you're tooling around full of gage in your hot rods , gorging yourselves on pizza and playing pinball in the taverns and generally behaving like Ubermenschen . In that case , listen to what befell another wisenheimer who tangled with our joss . A couple of years back , I occupied a Village apartment whose outer staircase contained the type of niche called a `` coffin turn '' . In it was a stone Tibetan Buddha I had picked up in Bombay , and occasionally , to make merit , my wife and I garlanded it with flowers or laid a few pennies in its lap . After a while , we became aware that the money was disappearing as fast as we replenished it . Our suspicions eventually centered , by the process of elimination , on a grocer's boy , a thoroughly bad hat , who delivered cartons to the people overhead . The more I probed into this young man's activities and character , the less savory I found him . I learned , for example , that he made a practice of yapping at dogs he encountered and , in winter , of sprinkling salt on the icy pavement to scarify their feet . His energy was prodigious ; ; sometimes he would be up before dawn , clad as a garbage collector and hurling pails into areaways to exasperate us , and thereafter would hurry to the Bronx Zoo to grimace at the lions and press cigar butts against their paws . Evenings , he was frequently to be seen at restaurants like Enrico & Paglieri's or Peter's Backyard drunkenly donning ladies' hats and singing `` O Sole Mio '' . In short , and to borrow an arboreal phrase , slash timber . Well , the odious little toad went along chivying animals and humans who couldn't retaliate , and in due course , as was inevitable , overreached himself . One morning , we discovered not only that the pennies were missing from the idol but that a cigarette had been stubbed out in its lap . `` Now he's bought it '' , said my wife contentedly . `` No divinity will hold still for that . He's really asking for it '' . And how right she was . The next time we saw him , he was a changed person ; ; he had aged thirty years , and his face , the color of tallow , was crisscrossed with wrinkles , as though it had been wrapped in chicken wire . Some sort of nemesis was haunting his footsteps , he told us in a quavering voice -- either an ape specter or Abe Spector , a process-server , we couldn't determine which . His eyes had the same dreadful rigid stare as Dr. Grimesby Roylott's when he was found before his open safe wearing the speckled band . The grocery the youth worked for soon tired of his depressing effect on customers , most of whom were sufficiently neurotic without the threat of incubi , and let him go . The beautiful , the satisfying part of his disintegration , however , was the masterly way the Buddha polished him off . Reduced to beggary , he at last got a job as office boy to a television producer . His hubris , deficiency of taste , and sadism carried him straightaway to the top . He evolved programs that plumbed new depths of bathos and besmirched whole networks , and quickly superseded his boss . Not long ago , I rode down with him in an elevator in Radio City ; ; he was talking to himself thirteen to the dozen and smoking two cigars at once , clearly a man in extremis . `` See that guy '' ? ? The operator asked pityingly . `` I wouldn't be in his shoes for all the rice in China . There's some kind of a nemesis haunting his footsteps '' . However one looks at it , therefore , I'd say that your horoscope for this autumn is the reverse of rosy . The inventory you acquired from me isn't going to be easy to move ; ; you can't very well sidle up to people on the street and ask if they want to buy a hot Bodhisattva . Additionally , since you're going to be hors de combat pretty soon with sprue , yaws , Delhi boil , the Granville wilt , liver fluke , bilharziasis , and a host of other complications of the hex you've aroused , you mustn't expect to be lionized socially . My advice , if you live long enough to continue your vocation , is that the next time you're attracted by the exotic , pass it up -- it's nothing but a headache . As you can count on me to do the same . Compassionately yours , S. J. Perelman revulsion in the desert the doors of the D train slid shut , and as I dropped into a seat and , exhaling , looked up across the aisle , the whole aviary in my head burst into song . She was a living doll and no mistake -- the blue-black bang , the wide cheekbones , olive-flushed , that betrayed the Cherokee strain in her Midwestern lineage , and the mouth whose only fault , in the novelist's carping phrase , was that the lower lip was a trifle too voluptuous . From what I was able to gauge in a swift , greedy glance , the figure inside the coral-colored boucle dress was stupefying .\n"
    }
   ],
   "source": [
    "print(\" \".join(brown.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<generator object bigrams at 0x129049270>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bigram corpus\n",
    "bigrams = nltk.bigrams(w.lower() for w in bigram_words)\n",
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "the'),\n ('the', 'praise'),\n ('praise', 'and'),\n ('and', 'thanks'),\n ('thanks', 'of'),\n ('of', 'the'),\n ('the', 'city'),\n ('city', 'of'),\n ('of', 'atlanta'),\n ('atlanta', \"''\"),\n (\"''\", 'for'),\n ('for', 'the'),\n ('the', 'manner'),\n ('manner', 'in'),\n ('in', 'which'),\n ('which', 'the'),\n ('the', 'election'),\n ('election', 'was'),\n ('was', 'conducted'),\n ('conducted', '*start_end*'),\n ('*start_end*', 'the'),\n ('the', 'september-october'),\n ('september-october', 'term'),\n ('term', 'jury'),\n ('jury', 'had'),\n ('had', 'been'),\n ('been', 'charged'),\n ('charged', 'by'),\n ('by', 'fulton'),\n ('fulton', 'superior'),\n ('superior', 'court'),\n ('court', 'judge'),\n ('judge', 'durwood'),\n ('durwood', 'pye'),\n ('pye', 'to'),\n ('to', 'investigate'),\n ('investigate', 'reports'),\n ('reports', 'of'),\n ('of', 'possible'),\n ('possible', '``'),\n ('``', 'irregularities'),\n ('irregularities', \"''\"),\n (\"''\", 'in'),\n ('in', 'the'),\n ('the', 'hard-fought'),\n ('hard-fought', 'primary'),\n ('primary', 'which'),\n ('which', 'was'),\n ('was', 'won'),\n ('won', 'by'),\n ('by', 'mayor-nominate'),\n ('mayor-nominate', 'ivan'),\n ('ivan', 'allen'),\n ('allen', 'jr.'),\n ('jr.', '*start_end*'),\n ('*start_end*', '``'),\n ('``', 'only'),\n ('only', 'a'),\n ('a', 'relative'),\n ('relative', 'handful'),\n ('handful', 'of'),\n ('of', 'such'),\n ('such', 'reports'),\n ('reports', 'was'),\n ('was', 'received'),\n ('received', \"''\"),\n (\"''\", ','),\n (',', 'the'),\n ('the', 'jury'),\n ('jury', 'said'),\n ('said', ','),\n (',', '``'),\n ('``', 'considering'),\n ('considering', 'the'),\n ('the', 'widespread'),\n ('widespread', 'interest'),\n ('interest', 'in'),\n ('in', 'the'),\n ('the', 'election'),\n ('election', ','),\n (',', 'the'),\n ('the', 'number'),\n ('number', 'of'),\n ('of', 'voters'),\n ('voters', 'and'),\n ('and', 'the'),\n ('the', 'size'),\n ('size', 'of'),\n ('of', 'this'),\n ('this', 'city'),\n ('city', \"''\"),\n (\"''\", '*start_end*'),\n ('*start_end*', 'the'),\n ('the', 'jury'),\n ('jury', 'said'),\n ('said', 'it'),\n ('it', 'did'),\n ('did', 'find'),\n ('find', 'that'),\n ('that', 'many'),\n ('many', 'of'),\n ('of', \"georgia's\"),\n (\"georgia's\", 'registration'),\n ('registration', 'and'),\n ('and', 'election'),\n ('election', 'laws'),\n ('laws', '``'),\n ('``', 'are'),\n ('are', 'outmoded'),\n ('outmoded', 'or'),\n ('or', 'inadequate'),\n ('inadequate', 'and'),\n ('and', 'often'),\n ('often', 'ambiguous'),\n ('ambiguous', \"''\"),\n (\"''\", '*start_end*'),\n ('*start_end*', 'it'),\n ('it', 'recommended'),\n ('recommended', 'that'),\n ('that', 'fulton'),\n ('fulton', 'legislators'),\n ('legislators', 'act'),\n ('act', '``'),\n ('``', 'to'),\n ('to', 'have'),\n ('have', 'these'),\n ('these', 'laws'),\n ('laws', 'studied'),\n ('studied', 'and'),\n ('and', 'revised'),\n ('revised', 'to'),\n ('to', 'the'),\n ('the', 'end'),\n ('end', 'of'),\n ('of', 'modernizing'),\n ('modernizing', 'and'),\n ('and', 'improving'),\n ('improving', 'them'),\n ('them', \"''\"),\n (\"''\", '*start_end*'),\n ('*start_end*', 'the'),\n ('the', 'grand'),\n ('grand', 'jury'),\n ('jury', 'commented'),\n ('commented', 'on'),\n ('on', 'a'),\n ('a', 'number'),\n ('number', 'of'),\n ('of', 'other'),\n ('other', 'topics'),\n ('topics', ','),\n (',', 'among'),\n ('among', 'them'),\n ('them', 'the'),\n ('the', 'atlanta'),\n ('atlanta', 'and'),\n ('and', 'fulton'),\n ('fulton', 'county'),\n ('county', 'purchasing'),\n ('purchasing', 'departments'),\n ('departments', 'which'),\n ('which', 'it'),\n ('it', 'said'),\n ('said', '``'),\n ('``', 'are'),\n ('are', 'well'),\n ('well', 'operated'),\n ('operated', 'and'),\n ('and', 'follow'),\n ('follow', 'generally'),\n ('generally', 'accepted'),\n ('accepted', 'practices'),\n ('practices', 'which'),\n ('which', 'inure'),\n ('inure', 'to'),\n ('to', 'the'),\n ('the', 'best'),\n ('best', 'interest'),\n ('interest', 'of'),\n ('of', 'both'),\n ('both', 'governments'),\n ('governments', \"''\"),\n (\"''\", '*start_end*'),\n ('*start_end*', 'merger'),\n ('merger', 'proposed'),\n ('proposed', 'however'),\n ('however', ','),\n (',', 'the'),\n ('the', 'jury'),\n ('jury', 'said'),\n ('said', 'it'),\n ('it', 'believes'),\n ('believes', '``'),\n ('``', 'these'),\n ('these', 'two'),\n ('two', 'offices'),\n ('offices', 'should'),\n ('should', 'be'),\n ('be', 'combined'),\n ('combined', 'to'),\n ('to', 'achieve'),\n ('achieve', 'greater'),\n ('greater', 'efficiency'),\n ('efficiency', 'and'),\n ('and', 'reduce'),\n ('reduce', 'the'),\n ('the', 'cost'),\n ('cost', 'of'),\n ('of', 'administration'),\n ('administration', \"''\"),\n (\"''\", '*start_end*'),\n ('*start_end*', 'the'),\n ('the', 'city'),\n ('city', 'purchasing'),\n ('purchasing', 'department'),\n ('department', ','),\n (',', 'the'),\n ('the', 'jury'),\n ('jury', 'said'),\n ('said', ','),\n (',', '``'),\n ('``', 'is'),\n ('is', 'lacking'),\n ('lacking', 'in'),\n ('in', 'experienced'),\n ('experienced', 'clerical'),\n ('clerical', 'personnel'),\n ('personnel', 'as'),\n ('as', 'a'),\n ('a', 'result'),\n ('result', 'of'),\n ('of', 'city'),\n ('city', 'personnel'),\n ('personnel', 'policies'),\n ('policies', \"''\"),\n (\"''\", '*start_end*'),\n ('*start_end*', 'it'),\n ('it', 'urged'),\n ('urged', 'that'),\n ('that', 'the'),\n ('the', 'city'),\n ('city', '``'),\n ('``', 'take'),\n ('take', 'steps'),\n ('steps', 'to'),\n ('to', 'remedy'),\n ('remedy', \"''\"),\n (\"''\", 'this'),\n ('this', 'problem'),\n ('problem', '*start_end*'),\n ('*start_end*', 'implementation'),\n ('implementation', 'of'),\n ('of', \"georgia's\"),\n (\"georgia's\", 'automobile'),\n ('automobile', 'title'),\n ('title', 'law'),\n ('law', 'was'),\n ('was', 'also'),\n ('also', 'recommended'),\n ('recommended', 'by'),\n ('by', 'the'),\n ('the', 'outgoing'),\n ('outgoing', 'jury'),\n ('jury', '*start_end*'),\n ('*start_end*', 'it'),\n ('it', 'urged'),\n ('urged', 'that'),\n ('that', 'the'),\n ('the', 'next'),\n ('next', 'legislature'),\n ('legislature', '``'),\n ('``', 'provide'),\n ('provide', 'enabling'),\n ('enabling', 'funds'),\n ('funds', 'and'),\n ('and', 're-set'),\n ('re-set', 'the'),\n ('the', 'effective'),\n ('effective', 'date'),\n ('date', 'so'),\n ('so', 'that'),\n ('that', 'an'),\n ('an', 'orderly'),\n ('orderly', 'implementation'),\n ('implementation', 'of'),\n ('of', 'the'),\n ('the', 'law'),\n ('law', 'may'),\n ('may', 'be'),\n ('be', 'effected'),\n ('effected', \"''\"),\n (\"''\", '*start_end*'),\n ('*start_end*', 'the'),\n ('the', 'grand'),\n ('grand', 'jury'),\n ('jury', 'took'),\n ('took', 'a'),\n ('a', 'swipe'),\n ('swipe', 'at'),\n ('at', 'the'),\n ('the', 'state'),\n ('state', 'welfare'),\n ('welfare', \"department's\"),\n (\"department's\", 'handling'),\n ('handling', 'of'),\n ('of', 'federal'),\n ('federal', 'funds'),\n ('funds', 'granted'),\n ('granted', 'for'),\n ('for', 'child'),\n ('child', 'welfare'),\n ('welfare', 'services'),\n ('services', 'in'),\n ('in', 'foster'),\n ('foster', 'homes'),\n ('homes', '*start_end*'),\n ('*start_end*', '``'),\n ('``', 'this'),\n ('this', 'is'),\n ('is', 'one'),\n ('one', 'of'),\n ('of', 'the'),\n ('the', 'major'),\n ('major', 'items'),\n ('items', 'in'),\n ('in', 'the'),\n ('the', 'fulton'),\n ('fulton', 'county'),\n ('county', 'general'),\n ('general', 'assistance'),\n ('assistance', 'program'),\n ('program', \"''\"),\n (\"''\", ','),\n (',', 'the'),\n ('the', 'jury'),\n ('jury', 'said'),\n ('said', ','),\n (',', 'but'),\n ('but', 'the'),\n ('the', 'state'),\n ('state', 'welfare'),\n ('welfare', 'department'),\n ('department', '``'),\n ('``', 'has'),\n ('has', 'seen'),\n ('seen', 'fit'),\n ('fit', 'to'),\n ('to', 'distribute'),\n ('distribute', 'these'),\n ('these', 'funds'),\n ('funds', 'through'),\n ('through', 'the'),\n ('the', 'welfare'),\n ('welfare', 'departments'),\n ('departments', 'of'),\n ('of', 'all'),\n ('all', 'the'),\n ('the', 'counties'),\n ('counties', 'in'),\n ('in', 'the'),\n ('the', 'state'),\n ('state', 'with'),\n ('with', 'the'),\n ('the', 'exception'),\n ('exception', 'of'),\n ('of', 'fulton'),\n ('fulton', 'county'),\n ('county', ','),\n (',', 'which'),\n ('which', 'receives'),\n ('receives', 'none'),\n ('none', 'of'),\n ('of', 'this'),\n ('this', 'money'),\n ('money', '*start_end*'),\n ('*start_end*', 'the'),\n ('the', 'jurors'),\n ('jurors', 'said'),\n ('said', 'they'),\n ('they', 'realize'),\n ('realize', '``'),\n ('``', 'a'),\n ('a', 'proportionate'),\n ('proportionate', 'distribution'),\n ('distribution', 'of'),\n ('of', 'these'),\n ('these', 'funds'),\n ('funds', 'might'),\n ('might', 'disable'),\n ('disable', 'this'),\n ('this', 'program'),\n ('program', 'in'),\n ('in', 'our'),\n ('our', 'less'),\n ('less', 'populous'),\n ('populous', 'counties'),\n ('counties', \"''\"),\n (\"''\", '*start_end*'),\n ('*start_end*', 'nevertheless'),\n ('nevertheless', ','),\n (',', '``'),\n ('``', 'we'),\n ('we', 'feel'),\n ('feel', 'that'),\n ('that', 'in'),\n ('in', 'the'),\n ('the', 'future'),\n ('future', 'fulton'),\n ('fulton', 'county'),\n ('county', 'should'),\n ('should', 'receive'),\n ('receive', 'some'),\n ('some', 'portion'),\n ('portion', 'of'),\n ('of', 'these'),\n ('these', 'available'),\n ('available', 'funds'),\n ('funds', \"''\"),\n (\"''\", ','),\n (',', 'the'),\n ('the', 'jurors'),\n ('jurors', 'said'),\n ('said', '*start_end*'),\n ('*start_end*', '``'),\n ('``', 'failure'),\n ('failure', 'to'),\n ('to', 'do'),\n ('do', 'this'),\n ('this', 'will'),\n ('will', 'continue'),\n ('continue', 'to'),\n ('to', 'place'),\n ('place', 'a'),\n ('a', 'disproportionate'),\n ('disproportionate', 'burden'),\n ('burden', \"''\"),\n (\"''\", 'on'),\n ('on', 'fulton'),\n ('fulton', 'taxpayers'),\n ('taxpayers', '*start_end*'),\n ('*start_end*', 'the'),\n ('the', 'jury'),\n ('jury', 'also'),\n ('also', 'commented'),\n ('commented', 'on'),\n ('on', 'the'),\n ('the', 'fulton'),\n ('fulton', \"ordinary's\"),\n (\"ordinary's\", 'court'),\n ('court', 'which'),\n ('which', 'has'),\n ('has', 'been'),\n ('been', 'under'),\n ('under', 'fire'),\n ('fire', 'for'),\n ('for', 'its'),\n ('its', 'practices'),\n ('practices', 'in'),\n ('in', 'the'),\n ('the', 'appointment'),\n ('appointment', 'of'),\n ('of', 'appraisers'),\n ('appraisers', ','),\n (',', 'guardians'),\n ('guardians', 'and'),\n ('and', 'administrators'),\n ('administrators', 'and'),\n ('and', 'the'),\n ('the', 'awarding'),\n ('awarding', 'of'),\n ('of', 'fees'),\n ('fees', 'and'),\n ('and', 'compensation'),\n ('compensation', '*start_end*'),\n ('*start_end*', 'wards'),\n ('wards', 'protected'),\n ('protected', 'the'),\n ('the', 'jury'),\n ('jury', 'said'),\n ('said', 'it'),\n ('it', 'found'),\n ('found', 'the'),\n ('the', 'court'),\n ('court', '``'),\n ('``', 'has'),\n ('has', 'incorporated'),\n ('incorporated', 'into'),\n ('into', 'its'),\n ('its', 'operating'),\n ('operating', 'procedures'),\n ('procedures', 'the'),\n ('the', 'recommendations'),\n ('recommendations', \"''\"),\n (\"''\", 'of'),\n ('of', 'two'),\n ('two', 'previous'),\n ('previous', 'grand'),\n ('grand', 'juries'),\n ('juries', ','),\n (',', 'the'),\n ('the', 'atlanta'),\n ('atlanta', 'bar'),\n ('bar', 'association'),\n ('association', 'and'),\n ('and', 'an'),\n ('an', 'interim'),\n ('interim', 'citizens'),\n ('citizens', 'committee'),\n ('committee', '*start_end*'),\n ('*start_end*', '``'),\n ('``', 'these'),\n ('these', 'actions'),\n ('actions', 'should'),\n ('should', 'serve'),\n ('serve', 'to'),\n ('to', 'protect'),\n ('protect', 'in'),\n ('in', 'fact'),\n ('fact', 'and'),\n ('and', 'in'),\n ('in', 'effect'),\n ('effect', 'the'),\n ('the', \"court's\"),\n (\"court's\", 'wards'),\n ('wards', 'from'),\n ('from', 'undue'),\n ('undue', 'costs'),\n ('costs', 'and'),\n ('and', 'its'),\n ('its', 'appointed'),\n ('appointed', 'and'),\n ('and', 'elected'),\n ('elected', 'servants'),\n ('servants', 'from'),\n ('from', 'unmeritorious'),\n ('unmeritorious', 'criticisms'),\n ('criticisms', \"''\"),\n (\"''\", ','),\n (',', 'the'),\n ('the', 'jury'),\n ('jury', 'said'),\n ('said', '*start_end*'),\n ('*start_end*', 'regarding'),\n ('regarding', \"atlanta's\"),\n (\"atlanta's\", 'new'),\n ('new', 'multi-million-dollar'),\n ('multi-million-dollar', 'airport'),\n ('airport', ','),\n (',', 'the'),\n ('the', 'jury'),\n ('jury', 'recommended'),\n ('recommended', '``'),\n ('``', 'that'),\n ('that', 'when'),\n ('when', 'the'),\n ('the', 'new'),\n ('new', 'management'),\n ('management', 'takes'),\n ('takes', 'charge'),\n ('charge', 'jan.'),\n ('jan.', '1'),\n ('1', 'the'),\n ('the', 'airport'),\n ('airport', 'be'),\n ('be', 'operated'),\n ('operated', 'in'),\n ('in', 'a'),\n ('a', 'manner'),\n ('manner', 'that'),\n ('that', 'will'),\n ('will', 'eliminate'),\n ('eliminate', 'political'),\n ('political', 'influences'),\n ('influences', \"''\"),\n (\"''\", '*start_end*'),\n ('*start_end*', 'the'),\n ('the', 'jury'),\n ('jury', 'did'),\n ('did', 'not'),\n ('not', 'elaborate'),\n ('elaborate', ','),\n (',', 'but'),\n ('but', 'it'),\n ('it', 'added'),\n ('added', 'that'),\n ('that', '``'),\n ('``', 'there'),\n ('there', 'should'),\n ('should', 'be'),\n ('be', 'periodic'),\n ('periodic', 'surveillance'),\n ('surveillance', 'of'),\n ('of', 'the'),\n ('the', 'pricing'),\n ('pricing', 'practices'),\n ('practices', 'of'),\n ('of', 'the'),\n ('the', 'concessionaires'),\n ('concessionaires', 'for'),\n ('for', 'the'),\n ('the', 'purpose'),\n ('purpose', 'of'),\n ('of', 'keeping'),\n ('keeping', 'the'),\n ('the', 'prices'),\n ('prices', 'reasonable'),\n ('reasonable', \"''\"),\n (\"''\", '*start_end*'),\n ('*start_end*', 'ask'),\n ('ask', 'jail'),\n ('jail', 'deputies'),\n ('deputies', 'on'),\n ('on', 'other'),\n ('other', 'matters'),\n ('matters', ','),\n (',', 'the'),\n ('the', 'jury'),\n ('jury', 'recommended'),\n ('recommended', 'that'),\n ('that', ':'),\n (':', '('),\n ('(', '1'),\n ('1', ')'),\n (')', 'four'),\n ('four', 'additional'),\n ('additional', 'deputies'),\n ('deputies', 'be'),\n ('be', 'employed'),\n ('employed', 'at'),\n ('at', 'the'),\n ('the', 'fulton'),\n ('fulton', 'county'),\n ('county', 'jail'),\n ('jail', 'and'),\n ('and', '``'),\n ('``', 'a'),\n ('a', 'doctor'),\n ('doctor', ','),\n (',', 'medical'),\n ('medical', 'intern'),\n ('intern', 'or'),\n ('or', 'extern'),\n ('extern', 'be'),\n ('be', 'employed'),\n ('employed', 'for'),\n ('for', 'night'),\n ('night', 'and'),\n ('and', 'weekend'),\n ('weekend', 'duty'),\n ('duty', 'at'),\n ('at', 'the'),\n ('the', 'jail'),\n ('jail', \"''\"),\n (\"''\", '*start_end*'),\n ('*start_end*', '('),\n ('(', '2'),\n ('2', ')'),\n (')', 'fulton'),\n ('fulton', 'legislators'),\n ('legislators', '``'),\n ('``', 'work'),\n ('work', 'with'),\n ('with', 'city'),\n ('city', 'officials'),\n ('officials', 'to'),\n ('to', 'pass'),\n ('pass', 'enabling'),\n ('enabling', 'legislation'),\n ('legislation', 'that'),\n ('that', 'will'),\n ('will', 'permit'),\n ('permit', 'the'),\n ('the', 'establishment'),\n ('establishment', 'of'),\n ('of', 'a'),\n ('a', 'fair'),\n ('fair', 'and'),\n ('and', 'equitable'),\n ('equitable', \"''\"),\n (\"''\", 'pension'),\n ('pension', 'plan'),\n ('plan', 'for'),\n ('for', 'city'),\n ('city', 'employes'),\n ('employes', '*start_end*'),\n ('*start_end*', 'the'),\n ('the', 'jury'),\n ('jury', 'praised'),\n ('praised', 'the'),\n ('the', 'administration'),\n ('administration', 'and'),\n ('and', 'operation'),\n ('operation', 'of'),\n ('of', 'the'),\n ('the', 'atlanta'),\n ('atlanta', 'police'),\n ('police', 'department'),\n ('department', ','),\n (',', 'the'),\n ('the', 'fulton'),\n ('fulton', 'tax'),\n ('tax', \"commissioner's\"),\n (\"commissioner's\", 'office'),\n ('office', ','),\n (',', 'the'),\n ('the', 'bellwood'),\n ('bellwood', 'and'),\n ('and', 'alpharetta'),\n ('alpharetta', 'prison'),\n ('prison', 'farms'),\n ('farms', ','),\n (',', 'grady'),\n ('grady', 'hospital'),\n ('hospital', 'and'),\n ('and', 'the'),\n ('the', 'fulton'),\n ('fulton', 'health'),\n ('health', 'department'),\n ('department', '*start_end*'),\n ('*start_end*', 'mayor'),\n ('mayor', 'william'),\n ('william', 'b.'),\n ('b.', 'hartsfield'),\n ('hartsfield', 'filed'),\n ('filed', 'suit'),\n ('suit', 'for'),\n ('for', 'divorce'),\n ('divorce', 'from'),\n ('from', 'his'),\n ('his', 'wife'),\n ('wife', ','),\n (',', 'pearl'),\n ('pearl', 'williams'),\n ('williams', 'hartsfield'),\n ('hartsfield', ','),\n (',', 'in'),\n ('in', 'fulton'),\n ('fulton', 'superior'),\n ('superior', 'court'),\n ('court', 'friday'),\n ('friday', '*start_end*'),\n ('*start_end*', 'his'),\n ('his', 'petition'),\n ('petition', 'charged'),\n ('charged', 'mental'),\n ('mental', 'cruelty'),\n ('cruelty', '*start_end*'),\n ('*start_end*', 'the'),\n ('the', 'couple'),\n ('couple', 'was'),\n ('was', 'married'),\n ('married', 'aug.'),\n ('aug.', '2'),\n ('2', ','),\n (',', '1913'),\n ('1913', '*start_end*'),\n ('*start_end*', 'they'),\n ('they', 'have'),\n ('have', 'a'),\n ('a', 'son'),\n ('son', ','),\n (',', 'william'),\n ('william', 'berry'),\n ('berry', 'jr.'),\n ('jr.', ','),\n (',', 'and'),\n ('and', 'a'),\n ('a', 'daughter'),\n ('daughter', ','),\n (',', 'mrs.'),\n ('mrs.', 'j.'),\n ('j.', 'm.'),\n ('m.', 'cheshire'),\n ('cheshire', 'of'),\n ('of', 'griffin'),\n ('griffin', '*start_end*'),\n ('*start_end*', 'attorneys'),\n ('attorneys', 'for'),\n ('for', 'the'),\n ('the', 'mayor'),\n ('mayor', 'said'),\n ('said', 'that'),\n ('that', 'an'),\n ('an', 'amicable'),\n ('amicable', 'property'),\n ('property', 'settlement'),\n ('settlement', 'has'),\n ('has', 'been'),\n ('been', 'agreed'),\n ('agreed', 'upon'),\n ('upon', '*start_end*'),\n ('*start_end*', 'the'),\n ('the', 'petition'),\n ('petition', 'listed'),\n ('listed', 'the'),\n ('the', \"mayor's\"),\n (\"mayor's\", 'occupation'),\n ('occupation', 'as'),\n ('as', '``'),\n ('``', 'attorney'),\n ('attorney', \"''\"),\n (\"''\", 'and'),\n ('and', 'his'),\n ('his', 'age'),\n ('age', 'as'),\n ('as', '71'),\n ('71', '*start_end*'),\n ('*start_end*', 'it'),\n ('it', 'listed'),\n ('listed', 'his'),\n ('his', \"wife's\"),\n (\"wife's\", 'age'),\n ('age', 'as'),\n ('as', '74'),\n ('74', 'and'),\n ('and', 'place'),\n ('place', 'of'),\n ('of', 'birth'),\n ('birth', 'as'),\n ('as', 'opelika'),\n ('opelika', ','),\n (',', 'ala.'),\n ('ala.', '*start_end*'),\n ('*start_end*', 'the'),\n ('the', 'petition'),\n ('petition', 'said'),\n ('said', 'that'),\n ('that', 'the'),\n ('the', 'couple'),\n ('couple', 'has'),\n ('has', 'not'),\n ('not', 'lived'),\n ('lived', 'together'),\n ('together', 'as'),\n ('as', 'man'),\n ('man', 'and'),\n ('and', 'wife'),\n ('wife', 'for'),\n ('for', 'more'),\n ('more', 'than'),\n ('than', 'a'),\n ('a', 'year'),\n ('year', '*start_end*'),\n ('*start_end*', 'the'),\n ('the', 'hartsfield'),\n ('hartsfield', 'home'),\n ('home', 'is'),\n ('is', 'at'),\n ('at', '637'),\n ('637', 'e.'),\n ('e.', 'pelham'),\n ('pelham', 'rd.'),\n ('rd.', 'aj'),\n ('aj', '*start_end*'),\n ('*start_end*', 'henry'),\n ('henry', 'l.'),\n ('l.', 'bowden'),\n ('bowden', 'was'),\n ('was', 'listed'),\n ('listed', 'on'),\n ('on', 'the'),\n ('the', 'petition'),\n ('petition', 'as'),\n ('as', 'the'),\n ('the', \"mayor's\"),\n (\"mayor's\", 'attorney'),\n ('attorney', '*start_end*'),\n ('*start_end*', 'hartsfield'),\n ('hartsfield', 'has'),\n ('has', 'been'),\n ('been', 'mayor'),\n ('mayor', 'of'),\n ('of', 'atlanta'),\n ('atlanta', ','),\n (',', 'with'),\n ('with', 'exception'),\n ('exception', 'of'),\n ('of', 'one'),\n ('one', 'brief'),\n ('brief', 'interlude'),\n ('interlude', ','),\n (',', 'since'),\n ('since', '1937'),\n ('1937', '*start_end*'),\n ('*start_end*', 'his'),\n ('his', 'political'),\n ('political', 'career'),\n ('career', 'goes'),\n ('goes', 'back'),\n ('back', 'to'),\n ('to', 'his'),\n ('his', 'election'),\n ('election', 'to'),\n ('to', 'city'),\n ('city', 'council'),\n ('council', 'in'),\n ('in', '1923'),\n ('1923', '*start_end*'),\n ('*start_end*', 'the'),\n ('the', \"mayor's\"),\n (\"mayor's\", 'present'),\n ('present', 'term'),\n ('term', 'of'),\n ('of', 'office'),\n ('office', 'expires'),\n ('expires', 'jan.'),\n ('jan.', '1'),\n ('1', '*start_end*'),\n ('*start_end*', 'he'),\n ('he', 'will'),\n ('will', 'be'),\n ('be', 'succeeded'),\n ('succeeded', 'by'),\n ('by', 'ivan'),\n ('ivan', 'allen'),\n ('allen', 'jr.'),\n ('jr.', ','),\n (',', 'who'),\n ('who', 'became'),\n ('became', 'a'),\n ('a', 'candidate'),\n ('candidate', 'in'),\n ('in', 'the'),\n ('the', 'sept.'),\n ('sept.', '13'),\n ('13', 'primary'),\n ('primary', 'after'),\n ('after', 'mayor'),\n ('mayor', 'hartsfield'),\n ('hartsfield', 'announced'),\n ('announced', 'that'),\n ('that', 'he'),\n ('he', 'would'),\n ('would', 'not'),\n ('not', 'run'),\n ('run', 'for'),\n ('for', 'reelection'),\n ('reelection', '*start_end*'),\n ('*start_end*', 'georgia'),\n ('georgia', 'republicans'),\n ('republicans', 'are'),\n ('are', 'getting'),\n ('getting', 'strong'),\n ('strong', 'encouragement'),\n ('encouragement', 'to'),\n ('to', 'enter'),\n ('enter', 'a'),\n ('a', 'candidate'),\n ('candidate', 'in'),\n ('in', 'the'),\n ('the', '1962'),\n ('1962', \"governor's\"),\n ...]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yDxTtteUPXs3",
    "outputId": "68815f6c-c7fa-4c35-e637-823a87e5f329"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConditionalFreqDist with 0 conditions>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bigram probabilities\n",
    "conditional_freq = nltk.ConditionalFreqDist(bigrams)\n",
    "conditional_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJFSEZEAPXox"
   },
   "outputs": [],
   "source": [
    "# Function to calculate bigram probability\n",
    "def get_bigram_probability(first,second):\n",
    "    \n",
    "    bigram_freq = conditional_freq[first][second]\n",
    "    unigram_freq = updated_uni_freq[first]\n",
    "\n",
    "    bigram_prob = (bigram_freq)/(unigram_freq)\n",
    "    \n",
    "    return bigram_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "GoFNKwaPPXaB",
    "outputId": "b74ef435-8ca5-44af-d879-3f325db4faff"
   },
   "outputs": [],
   "source": [
    "## Calculating the bigram probability\n",
    "\n",
    "prob_list=[]\n",
    "previous = '*start_end*'\n",
    "\n",
    "for token in test_sentence_tokens:\n",
    "    next_probability = get_bigram_probability(previous,token)\n",
    "    print(previous,token,(float('%.3g' % next_probability)))\n",
    "    previous = token\n",
    "    prob_list.append(next_probability)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "Vq9D0Elulhbl",
    "outputId": "7daec848-be67-4346-980a-4308bec73c85"
   },
   "outputs": [],
   "source": [
    "# Creating bigrams\n",
    "\n",
    "bigram_words = []\n",
    "previous = 'EMPTY'\n",
    "sentences = 0\n",
    "for word in words:\n",
    "    if previous in ['EMPTY','.','?','!']:\n",
    "        ## insert word_boundaries at beginning of Brown,\n",
    "        bigram_words.append('*start_end*')\n",
    "    else:\n",
    "        bigram_words.append(word)\n",
    "    \n",
    "    previous = word\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "bigram_words.append('*start_end*') ## assume one additional *start_end* at the end of Brown\n",
    "\n",
    "updated_uni_freq  = nltk.FreqDist(w.lower() for w in bigram_words)\n",
    "\n",
    "\n",
    "print('Calculating bigram probalities for sentence, including bigrams with sentence boundaries, i.e., *start_end*')\n",
    "\n",
    "\n",
    "# Bigram corpus\n",
    "bigrams = nltk.bigrams(w.lower() for w in bigram_words)\n",
    "\n",
    "\n",
    "# Bigram probabilities\n",
    "conditional_freq = nltk.ConditionalFreqDist(bigrams)\n",
    "\n",
    "\n",
    "\n",
    "# Code begins here\n",
    "\n",
    "\n",
    "# Function to calculate bigram probability\n",
    "def get_bigram_probability(first,second):\n",
    "    \n",
    "    bigram_freq = conditional_freq[first][second]\n",
    "    unigram_freq = updated_uni_freq[first]\n",
    "\n",
    "    bigram_prob = (bigram_freq)/(unigram_freq) #without Laplacian smoothing\n",
    "\n",
    "    \n",
    "    return bigram_prob\n",
    "\n",
    "## Calculating the bigram probability\n",
    "\n",
    "prob_list=[]\n",
    "previous = '*start_end*'\n",
    "\n",
    "for token in test_sentence_tokens:\n",
    "    next_probability = get_bigram_probability(previous,token)\n",
    "    print(previous,token,(float('%.3g' % next_probability)))\n",
    "    previous = token\n",
    "    prob_list.append(next_probability)\n",
    "\n",
    "\n",
    "    \n",
    "# For the final term    \n",
    "next_probability = get_bigram_probability(previous,'*start_end*')\n",
    "print(previous,'*start_end*',next_probability)\n",
    "prob_list.append(next_probability)    \n",
    "\n",
    "print(prob_list)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "phWw7hty3PXm"
   },
   "source": [
    "##Find the perplexity and total probabilities of the given sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YckL36_wQ_nJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_nsIGYlQ_hq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rnpHhJteQ_W-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LbmJnULf212C",
    "outputId": "54f7d1ef-f5bb-4a3e-d183-4620dab11a51"
   },
   "outputs": [],
   "source": [
    "prob_list=[0.1, 0.023 ,0.09]\n",
    "\n",
    "\n",
    "perplexity=1\n",
    "\n",
    "# Calculating N\n",
    "N=len(prob_list)-1\n",
    "\n",
    "\n",
    "# Calculating the perplexity\n",
    "for val in prob_list:\n",
    "    perplexity = perplexity * (1/val)\n",
    "\n",
    "perplexity = pow(perplexity, 1/float(N)) \n",
    "\n",
    "print(\"Perplexity= :\",perplexity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "7or2sSfW3d6o",
    "outputId": "733ffa87-8271-4aa8-8a44-971297902543"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"For the sentence: 'this is a sunny day' \"\"\" \n",
    "prob_list_1=[0.008303975842979365, 0.05030826140567201, 0.08609535184632229, 4.5083630133898384e-05, 0.15384615384615385]\n",
    "\n",
    "\n",
    "\n",
    "total_prob_1 = 1\n",
    "\n",
    "# Multiplying all the values of the probability and storing it\n",
    "for val in prob_list_1:\n",
    "    total_prob_1 *= val\n",
    "\n",
    "\n",
    "print(\"For the sentence- 'this is a sunny day'\")\n",
    "print(\"Total probability:\",total_prob_1)\n",
    "\n",
    "\n",
    "perplexity_1=1\n",
    "\n",
    "# Calculating N\n",
    "N=len(prob_list_1)-1\n",
    "\n",
    "\n",
    "# Calculating the perplexity\n",
    "for val in prob_list_1:\n",
    "    perplexity_1 = perplexity_1 * (1/val)\n",
    "\n",
    "perplexity_1 = pow(perplexity_1, 1/float(N)) \n",
    "\n",
    "print(\"Perplexity:\",perplexity_1)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"For the sentence: 'this place is beautiful' \"\"\"\n",
    "prob_list_2=[0.008303975842979365, 0.0022194821208384712, 0.02185792349726776, 9.953219866626854e-05]\n",
    "\n",
    "total_prob_2 = 1\n",
    "\n",
    "# Multiplying all the values of the probability and storing it\n",
    "for val in prob_list_2:\n",
    "    total_prob_2 *= val\n",
    "\n",
    "print(\"\\n\\nFor the sentence- 'this place is beautiful'\")    \n",
    "print(\"Total probability: \",total_prob_2)\n",
    "\n",
    "\n",
    "perplexity_2=1\n",
    "\n",
    "# Calculating N\n",
    "N=len(prob_list_2)-1\n",
    "\n",
    "# Calculating perplexity\n",
    "for val in prob_list_2:\n",
    "    perplexity_2 = perplexity_2 * (1/val)\n",
    "\n",
    "perplexity_2 = pow(perplexity_2, 1/float(N)) \n",
    "\n",
    "print(\"Perplexity: \",perplexity_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VZZX7KkDSF0Z"
   },
   "outputs": [],
   "source": [
    "# Naive Bayes Model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z8NpG8apSFke"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFbNJURr4dYV"
   },
   "source": [
    "##Calculate the probability using Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "LhlEVNGq3hxa",
    "outputId": "7f3bdf42-599a-44c2-a3dd-81a0d9a9b6f2"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# Corpus\n",
    "words = brown.words()\n",
    "words=[w.lower() for w in words]\n",
    "\n",
    "# Unigram frequency \n",
    "uni_freq = nltk.FreqDist(w.lower() for w in words)\n",
    "\n",
    "# Size of corpus\n",
    "total_words = len(words)\n",
    "\n",
    "print('Frequency of tokens of the sample sentence:')\n",
    "\n",
    "for word in test_sentence_tokens:\n",
    "    print(word,uni_freq[word])\n",
    "\n",
    "    \n",
    "# Creating bigrams\n",
    "\n",
    "bigram_words = []\n",
    "previous = 'EMPTY'\n",
    "sentences = 0\n",
    "for word in words:\n",
    "    if previous in ['EMPTY','.','?','!']:\n",
    "        ## insert word_boundaries at beginning of Brown,\n",
    "        bigram_words.append('*start_end*')\n",
    "    else:\n",
    "        bigram_words.append(word)\n",
    "    \n",
    "    previous = word\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "bigram_words.append('*start_end*') ## assume one additional *start_end* at the end of Brown\n",
    "\n",
    "updated_uni_freq  = nltk.FreqDist(w.lower() for w in bigram_words)\n",
    "\n",
    "\n",
    "print('\\nCalculating bigram counts for sentence, including bigrams with sentence boundaries, i.e., *BEGIN* and *END*')\n",
    "\n",
    "\n",
    "# Bigram corpus\n",
    "bigrams = nltk.bigrams(w.lower() for w in bigram_words)\n",
    "\n",
    "\n",
    "# Bigram probabilities\n",
    "conditional_freq = nltk.ConditionalFreqDist(bigrams)\n",
    "\n",
    "#Sentence \n",
    "test_sentence_tokens=['sunset','looks','magnificient','.']\n",
    "\n",
    "# Code begins here\n",
    "\n",
    "\n",
    "\n",
    "V=len(set(words))\n",
    "\n",
    "\n",
    "# Function to calculate bigram probability\n",
    "def get_bigram_probability(first,second):\n",
    "    \n",
    "    bigram_freq = conditional_freq[first][second]\n",
    "    unigram_freq = updated_uni_freq[first]\n",
    "\n",
    "    bigram_prob = (bigram_freq + 1)/(unigram_freq + V) # with Laplacian Smoothing\n",
    "    \n",
    "    return bigram_prob\n",
    "\n",
    "# Calculating the bigram probability\n",
    "\n",
    "prob_list=[]\n",
    "previous = '*start_end*'\n",
    "for token in test_sentence_tokens:\n",
    "    next_probability = get_bigram_probability(previous,token)\n",
    "    print(previous,token,(float('%.3g' % next_probability)))\n",
    "    previous = token\n",
    "    prob_list.append(next_probability)\n",
    "\n",
    "    \n",
    "# For the final term    \n",
    "next_probability = get_bigram_probability(previous,'*start_end*')\n",
    "print(previous,'*start_end*',next_probability)\n",
    "prob_list.append(next_probability)    \n",
    "\n",
    "print(prob_list)    \n",
    "\n",
    "\n",
    "\n",
    "# Calculating the total probability\n",
    "\n",
    "total_prob = 1\n",
    "for val in prob_list:\n",
    "    total_prob *= val\n",
    "\n",
    "print(\"\\nTotal probability:\",total_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k7nJg8bI5fJ2"
   },
   "source": [
    "##Calculate the probability using Backoff method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "_9bP7Ub85cQk",
    "outputId": "2ef332ea-1139-42f5-99cc-8f2e9b68238a"
   },
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "#Sentence \n",
    "test_sentence_tokens=['this','is','a','very','sunny','day','.']\n",
    "\n",
    "\n",
    "# Corpus\n",
    "words = brown.words()\n",
    "words=[w.lower() for w in words]\n",
    "\n",
    "# Unigram frequency \n",
    "uni_freq = nltk.FreqDist(w.lower() for w in words)\n",
    "\n",
    "# Size of corpus\n",
    "total_words = len(words)\n",
    "\n",
    "print('Frequency of tokens of the sample sentence:')\n",
    "\n",
    "for word in test_sentence_tokens:\n",
    "    print(word,uni_freq[word])\n",
    "\n",
    "    \n",
    "# Creating bigrams\n",
    "\n",
    "bigram_words = []\n",
    "previous = 'EMPTY'\n",
    "sentences = 0\n",
    "for word in words:\n",
    "    if previous in ['EMPTY','.','?','!']:\n",
    "        ## insert word_boundaries at beginning of Brown,\n",
    "        bigram_words.append('*start_end*')\n",
    "    else:\n",
    "        bigram_words.append(word)\n",
    "    \n",
    "    previous = word\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "bigram_words.append('*start_end*') ## assume one additional *start_end* at the end of Brown\n",
    "\n",
    "updated_uni_freq  = nltk.FreqDist(w.lower() for w in bigram_words)\n",
    "\n",
    "\n",
    "print('\\nCalculating bigram counts for sentence, including bigrams with sentence boundaries, i.e., *BEGIN* and *END*')\n",
    "\n",
    "\n",
    "# Bigram corpus\n",
    "bigrams = nltk.bigrams(w.lower() for w in bigram_words)\n",
    "\n",
    "\n",
    "# Bigram probabilities\n",
    "conditional_freq = nltk.ConditionalFreqDist(bigrams)\n",
    "\n",
    "\n",
    "# Code begins here\n",
    "\n",
    "\n",
    "V=len(set(words))\n",
    "\n",
    "\n",
    "# Function to calculate bigram probability\n",
    "def get_bigram_probability(first,second):\n",
    "\n",
    "    if not second in conditional_freq[first]:\n",
    "        print('Backing Off to Unigram Probability for',second)\n",
    "        unigram_prob = updated_uni_freq[second]/len(words)\n",
    "        return unigram_prob \n",
    "    \n",
    "\n",
    "    bigram_freq = conditional_freq[first][second]\n",
    "    unigram_freq = updated_uni_freq[first]\n",
    "    bigram_prob = bigram_freq/unigram_freq\n",
    "    \n",
    "    return bigram_prob\n",
    "\n",
    "\n",
    "# Calculating the bigram probability\n",
    "\n",
    "prob_list=[]\n",
    "previous = '*start_end*'\n",
    "for token in test_sentence_tokens:\n",
    "    next_probability = get_bigram_probability(previous,token)\n",
    "    print(previous,token,(float('%.3g' % next_probability)))\n",
    "    previous = token\n",
    "    prob_list.append(next_probability)\n",
    "\n",
    "    \n",
    "# For the final term    \n",
    "next_probability = get_bigram_probability(previous,'*start_end*')\n",
    "print(previous,'*start_end*',next_probability)\n",
    "prob_list.append(next_probability)    \n",
    "\n",
    "print(prob_list)    \n",
    "\n",
    "\n",
    "\n",
    "# Calculating the total probability\n",
    "\n",
    "total_prob = 1\n",
    "for val in prob_list:\n",
    "    total_prob *= val\n",
    "\n",
    "print(\"\\nTotal probability:\",total_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgavtcD25vdc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Language_models_code_along.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}