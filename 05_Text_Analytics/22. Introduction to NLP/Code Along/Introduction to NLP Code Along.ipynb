{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>20 Newsgroups data</center>\n",
    "\n",
    "The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. To the best of my knowledge, it was originally collected by Ken Lang, probably for his Newsweeder: Learning to filter netnews paper, though he does not explicitly mention this collection. The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.\n",
    "\n",
    "\n",
    "\n",
    "## About the dataset\n",
    "The data is organized into 20 different newsgroups, each corresponding to a different topic. Some of the newsgroups are very closely related to each other (e.g. comp.sys.ibm.pc.hardware / comp.sys.mac.hardware), while others are highly unrelated (e.g misc.forsale / soc.religion.christian). Here is a list of the 20 newsgroups, partitioned (more or less) according to subject matter:\n",
    "\n",
    "```python\n",
    "comp.graphics\n",
    "comp.os.ms-windows.misc\n",
    "comp.sys.ibm.pc.hardware\n",
    "comp.sys.mac.hardware\n",
    "comp.windows.x\t\n",
    "rec.autos\n",
    "rec.motorcycles\n",
    "rec.sport.baseball\n",
    "rec.sport.hockey\n",
    "sci.crypt\n",
    "sci.electronics\n",
    "sci.med\n",
    "sci.space\n",
    "misc.forsale\t\n",
    "talk.politics.misc\n",
    "talk.politics.guns\n",
    "talk.politics.mideast\n",
    "talk.religion.misc\n",
    "alt.atheism\n",
    "soc.religion.christian\n",
    "```\n",
    "\n",
    "The dataset used in this example is the 20 newsgroups dataset which will be automatically downloaded and then cached and reused for the document classification example.\n",
    "\n",
    "You can adjust the number of categories by giving their names to the dataset loader or setting them to None to get the 20 of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score , f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize, corpus, tokenize\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "df = fetch_20newsgroups(subset='train')\n",
    "pprint(list(df.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Create a list of 4 newsgroup and fetch it using function `fetch_20newsgroups` for both train and test data.\n",
    "***\n",
    "### Instructions\n",
    "\n",
    "- Create a list of 4 newsgroup i.e `'alt.atheism'`, `'talk.religion.misc'`, `'comp.graphics'`, `'sci.space'` and save it as `categories`\n",
    "- Fetch 4 newsgroup using function `fetch_20newsgroups` with parameters as `subset='train'`,`categories=categories` and store it in `newsgroups_train` variable. Similarly do it for test and store in `newsgroups_test`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Use TfidfVectorizer on train data and find out the Number of Non-Zero components per sample.\n",
    "***\n",
    "### Instructions\n",
    " - Initialise a `TfidfVectorizer()` object and save it as `vectorizer`\n",
    " - Apply the \"fit_transform()\" method of `vectorizer` on `newsgroups_train.data` and store the result in `vectors`\n",
    " - Print the distribution count of the `vectors`\n",
    " - Find out the Number of Non-Zero components per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectorizer.fit_transform(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 34118)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159.0132743362832"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.nnz / float(vectors.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Use TfidfVectorizer on test data and apply Naive Bayes model and calculate f1_score.\n",
    "***\n",
    "### Instructions\n",
    "- Apply the `transform()` method  on `newsgroups_test.data` and store the result in `vectors_test`\n",
    "- Initialise a naive bayes model with `MultinomialNB()` having parameter as `alpha=.01` and save it to a variable called `clf`\n",
    "- Apply the `fit()` method of `clf` on `vectors` and `newsgroups_train.target`\n",
    "- Predict on test data i.e `vectors_test` and save it as `pred`\n",
    "- Find out the f1 score between `newsgroups_test.target` and `pred` using the `f1_score` method also pass parameter as `average = 'macro'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_test = vectorizer.transform(newsgroups_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(vectors, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8821359240272957"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(newsgroups_test.target, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '0000', ..., 'ªl',\n",
       "       'º_________________________________________________º_____________________º',\n",
       "       'ºnd'], dtype='<U80')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Print the top 20 news category and top 20 words for every news category.\n",
    "***\n",
    "As we see that Multinomial Naive Bayes gets a higher F-score of 0.88. You might be thinking what’s going on inside this classifier?\n",
    "\n",
    "Let’s take a look at what the most informative features are:\n",
    "- Create a function `show_top20` with 3 parameters as `classifier`, `vectorizer`, `categories`\n",
    "- Get the feature names using `get_feature_names()` attribute of `vectorizer` and convert it into array and save it as `feature_names`.\n",
    "- Start a `for` loop to iterate over both the index and value of `categories` using `enumerate()` function\n",
    "- Inside the for loop, sort the top 20 coefficient using `argsort()` function of numpy by passing parameter as `classifier.coef_[i][-20]` and save it as in variable `top20`\n",
    "- Print out the corresponding value (`categories` i.e. news category) and top 20 words for every news category\n",
    "- And then call the function as `show_top20(clf, vectorizer, newsgroups_train.target_names)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top20(classifier, vectorizer, categories):\n",
    "    feature_name = np.asarray(vectorizer.get_feature_names())\n",
    "    for index, value in enumerate(categories):\n",
    "        top20 = np.argsort(classifier.coef_[index])[-20:]\n",
    "        print('%s: %s' %(value, \" \".join(feature_name[top20])))\n",
    "        print(value, top20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: for com as have this be god are keith not edu it and in you that is of to the\n",
      "alt.atheism [14274  9122  5750 15885 30763  6503 15190  5622 18569 22331 12363 17962\n",
      "  5217 17052 33957 30641 17889 22657 30993 30643]\n",
      "comp.graphics: university any can or have this on you that from edu in graphics it is for and of to the\n",
      "comp.graphics [32015  5379  7953 22901 15885 30763 22772 33957 30641 14535 12363 17052\n",
      " 15369 17962 17889 14274  5217 22657 30993 30643]\n",
      "sci.space: access from this henry was be you on for nasa edu it that is in and space to of the\n",
      "sci.space [ 4318 14535 30763 16068 33078  6503 33957 22772 14274 21788 12363 17962\n",
      " 30641 17889 17052  5217 28842 30993 22657 30643]\n",
      "talk.religion.misc: for be this as he sandvik are edu god com not it you in is that and to of the\n",
      "talk.religion.misc [14274  6503 30763  5750 15921 27333  5622 12363 15190  9122 22331 17962\n",
      " 33957 17052 17889 30641  5217 30993 22657 30643]\n"
     ]
    }
   ],
   "source": [
    "show_top20(clf, vectorizer, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 alt.atheism\n",
      "1 talk.religion.misc\n",
      "2 comp.graphics\n",
      "3 sci.space\n"
     ]
    }
   ],
   "source": [
    "for index, value in enumerate(categories):\n",
    "    print(index, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 34118), dtype=float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_[0 : -20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
