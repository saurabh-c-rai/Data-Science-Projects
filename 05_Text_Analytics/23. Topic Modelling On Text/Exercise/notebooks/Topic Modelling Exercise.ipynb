{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"After a five year struggle, creditors of the collapsed, fraud-ridden BCCI will receive a payment of $2.65 billion on Tuesday, equal to 24.5 percent of their claims, a spokesman for the liquidators said on Monday.\\nBank of Credit and Commerce International, founded in 1972, was closed by central banks in 1991 and collapsed with debts of more than $12 billion when evidence of massive fraud and money laundering was unearthed leading to a tangled web of litigation which shows no sign of reaching an early conclusion.\\nBCCI had assets of $24 billion and operations in 71 countries at the time of its collapse.\\nLiquidator Deloitte and Touche said a further payment, reportedly of 10 percent, of the admitted claims which total some $10.5 billion should be made in the next 12 to 16 months.\\nThe gross fund of amounts recovered by the liquidators stands at around $4.0 billion and includes $1.5 billion paid by BCCI's majority shareholder, the government of Abu Dhabi, which will pay a further $250 million in due course following a settlement reached earlier this year.\\nThis, in addition to efforts by US authorities which resulted in the recovery of more than $500 million from the United States paved the way for the first dividend payment.\\nA further $245 million was paid by Saudi billionaire Sheikh Khalid bin Mahfouz who the liquidators alleged was involved in covering up the BCCI scandal. Under a 1995 Luxembourg court settlement, Mahfouz agreed to pay without admitting liability, in return for the lawsuits being dropped.\\nThe liquidators still have outstanding claims against the Bank of England, the Institut Monetaire Luxembourgeois (BCCI's operations were based in Luxembourgh) and the auditors of the bank, international accountancy firms Price Waterhouse and Ernst &amp; Whinney, now part of the merged Ernst &amp; Young.\\nPrice Waterhouse has said it is making a multi-billion dollar counter claim against Abu Dhabi.\\nFurther law suits are also pending around the world in an attempt to recover further amounts.\\nThe two biggest groups of creditors of BCCI are in the United Arab Emirates (UAE) and in Britain.\\nThe English liquidators of BCCI, Deloite &amp; Touche, have recovered over $1 billion and have been paid a massive $200 million in fees.\\nIn a report to the High Court earlier this year, the liquidator said legal fees in the liquidation ammounted to over $75 million so far.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "Text = open('../data/C50train/JoeOrtiz/242939newsML.txt').read()\n",
    "Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 1 \n",
    "***\n",
    "### Instructions\n",
    "* Perform a sentence tokenization on the above data using `sent_tokenize()` and store it in a variable called '**Sent**'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sent = nltk.sent_tokenize(Text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 2 \n",
    "***\n",
    "**Bag of Words** <br>\n",
    "In this task, we will try to do the basic NLP operations of tokenizing, removing stop words and lemmatizing on our data. We will also try to create a list of most frequent words\n",
    "### Instructions\n",
    "- Iterate over every Sentence in the list **Sent**  using a for loop and convert every sentence into \n",
    "    - lower case \n",
    "    - and then tokenize it using the instantiated object \n",
    "- Now remove the stopwords from the tokens \n",
    "- Lemmatize them using `WordNetLemmatizer()` and save it in `lemmatized_tokens`\n",
    "- Append `lemmatized_tokens` into the list called **Text**\n",
    "- Convert `Counter(lemmatized_tokens)` into dictionary and save it in a variable called `BoW_dict`.\n",
    "- Sort `BoW_dict` in descending order using `sorted()` function with the parameters `BoW_dict.items()`, `key=operator.itemgetter(1)`, `reverse=True`. Store it in a variable called `sorted_d`\n",
    "- Finally append them into the list called **Texts** \n",
    "- Print `Texts` to check out the list of words with their frequency in descending order.\n",
    "- Print Top 10 words from the `Texts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lema = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/raisaurabh04/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Texts = []\n",
    "Text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in Sent:\n",
    "    raw = sentence.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    lemmatized_tokens = [Lema.lemmatize(i) for i in stopped_tokens]\n",
    "    Text.append(lemmatized_tokens)\n",
    "    BoW_dict = dict(Counter(lemmatized_tokens))\n",
    "    sorted_d = sorted(BoW_dict.items(), key = operator.itemgetter(1), reverse=True)\n",
    "    Texts.append(sorted_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('five', 1), ('year', 1), ('struggle', 1), ('creditor', 1), ('collapsed', 1), ('fraud', 1), ('ridden', 1), ('bcci', 1), ('receive', 1), ('payment', 1), ('2', 1), ('65', 1), ('billion', 1), ('tuesday', 1), ('equal', 1), ('24', 1), ('5', 1), ('percent', 1), ('claim', 1), ('spokesman', 1), ('liquidator', 1), ('said', 1), ('monday', 1)], [('bank', 2), ('credit', 1), ('commerce', 1), ('international', 1), ('founded', 1), ('1972', 1), ('closed', 1), ('central', 1), ('1991', 1), ('collapsed', 1), ('debt', 1), ('12', 1), ('billion', 1), ('evidence', 1), ('massive', 1), ('fraud', 1), ('money', 1), ('laundering', 1), ('unearthed', 1), ('leading', 1), ('tangled', 1), ('web', 1), ('litigation', 1), ('show', 1), ('sign', 1), ('reaching', 1), ('early', 1), ('conclusion', 1)], [('bcci', 1), ('asset', 1), ('24', 1), ('billion', 1), ('operation', 1), ('71', 1), ('country', 1), ('time', 1), ('collapse', 1)], [('10', 2), ('liquidator', 1), ('deloitte', 1), ('touche', 1), ('said', 1), ('payment', 1), ('reportedly', 1), ('percent', 1), ('admitted', 1), ('claim', 1), ('total', 1), ('5', 1), ('billion', 1), ('made', 1), ('next', 1), ('12', 1), ('16', 1), ('month', 1)], [('billion', 2), ('gross', 1), ('fund', 1), ('amount', 1), ('recovered', 1), ('liquidator', 1), ('stand', 1), ('around', 1), ('4', 1), ('0', 1), ('includes', 1), ('1', 1), ('5', 1), ('paid', 1), ('bcci', 1), ('majority', 1), ('shareholder', 1), ('government', 1), ('abu', 1), ('dhabi', 1), ('pay', 1), ('250', 1), ('million', 1), ('due', 1), ('course', 1), ('following', 1), ('settlement', 1), ('reached', 1), ('earlier', 1), ('year', 1)], [('addition', 1), ('effort', 1), ('u', 1), ('authority', 1), ('resulted', 1), ('recovery', 1), ('500', 1), ('million', 1), ('united', 1), ('state', 1), ('paved', 1), ('way', 1), ('first', 1), ('dividend', 1), ('payment', 1)], [('245', 1), ('million', 1), ('paid', 1), ('saudi', 1), ('billionaire', 1), ('sheikh', 1), ('khalid', 1), ('bin', 1), ('mahfouz', 1), ('liquidator', 1), ('alleged', 1), ('involved', 1), ('covering', 1), ('bcci', 1), ('scandal', 1)], [('1995', 1), ('luxembourg', 1), ('court', 1), ('settlement', 1), ('mahfouz', 1), ('agreed', 1), ('pay', 1), ('without', 1), ('admitting', 1), ('liability', 1), ('return', 1), ('lawsuit', 1), ('dropped', 1)], [('bank', 2), ('ernst', 2), ('amp', 2), ('liquidator', 1), ('still', 1), ('outstanding', 1), ('claim', 1), ('england', 1), ('institut', 1), ('monetaire', 1), ('luxembourgeois', 1), ('bcci', 1), ('operation', 1), ('based', 1), ('luxembourgh', 1), ('auditor', 1), ('international', 1), ('accountancy', 1), ('firm', 1), ('price', 1), ('waterhouse', 1), ('whinney', 1), ('part', 1), ('merged', 1), ('young', 1)], [('price', 1), ('waterhouse', 1), ('said', 1), ('making', 1), ('multi', 1), ('billion', 1), ('dollar', 1), ('counter', 1), ('claim', 1), ('abu', 1), ('dhabi', 1)], [('law', 1), ('suit', 1), ('also', 1), ('pending', 1), ('around', 1), ('world', 1), ('attempt', 1), ('recover', 1), ('amount', 1)], [('two', 1), ('biggest', 1), ('group', 1), ('creditor', 1), ('bcci', 1), ('united', 1), ('arab', 1), ('emirate', 1), ('uae', 1), ('britain', 1)], [('english', 1), ('liquidator', 1), ('bcci', 1), ('deloite', 1), ('amp', 1), ('touche', 1), ('recovered', 1), ('1', 1), ('billion', 1), ('paid', 1), ('massive', 1), ('200', 1), ('million', 1), ('fee', 1)], [('report', 1), ('high', 1), ('court', 1), ('earlier', 1), ('year', 1), ('liquidator', 1), ('said', 1), ('legal', 1), ('fee', 1), ('liquidation', 1), ('ammounted', 1), ('75', 1), ('million', 1), ('far', 1)]]\n",
      "\n",
      "Top 10 word:\n",
      " [('report', 1), ('high', 1), ('court', 1), ('earlier', 1), ('year', 1), ('liquidator', 1), ('said', 1), ('legal', 1), ('fee', 1), ('liquidation', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(Texts)\n",
    "top_words = sorted_d[ :  10]\n",
    "print('\\nTop 10 word:\\n', sorted_d[ : 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 3\n",
    "***\n",
    "Since Nouns are important in Topic Modeling process, we will try to figure out the top nouns from the bag of words we created in the last task.\n",
    "### Instructions\n",
    "- Join the previously created bag of words `lemmatized_tokens` back into a string using `join()` method and store the result in `BoW_joined`.\n",
    "- Convert `Bow_joined` into a textblob using `TextBlob()` method and store the result into `blob`.\n",
    "- Print out the `blob.tags` to look at the different tags associated with the words.\n",
    "- Get the tags of all the words from `lemmatized_tokens` using `blob.tags` and store the result in a variable called `tags`\n",
    "- From `tags`, extract the words which have `NN` tags and store them to a list called `nouns`\n",
    "- The top 10 words which have appeared most frequently are already stored into a list called `top_words`\n",
    "- Compare the two lists `top_words` and `nouns` and store the common elements between them in a new list called `top_nouns`\n",
    "- Print `top_nouns` to see most commonly appearing nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/raisaurabh04/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BoW_joined = ' '.join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(BoW_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = []\n",
    "for word, tag in blob.tags:\n",
    "    if tag == 'NN' :\n",
    "        nouns.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('report', 'NN'), ('high', 'JJ'), ('court', 'NN'), ('earlier', 'RBR'), ('year', 'NN'), ('liquidator', 'NN'), ('said', 'VBD'), ('legal', 'JJ'), ('fee', 'NN'), ('liquidation', 'NN'), ('ammounted', 'VBD'), ('75', 'CD'), ('million', 'CD'), ('far', 'RB')]\n"
     ]
    }
   ],
   "source": [
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_nouns = []\n",
    "for noun, importance in top_words:\n",
    "    if noun in nouns:\n",
    "        top_nouns.append(noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['report', 'court', 'year', 'liquidator', 'fee', 'liquidation']\n",
      "[('report', 1), ('high', 1), ('court', 1), ('earlier', 1), ('year', 1), ('liquidator', 1), ('said', 1), ('legal', 1), ('fee', 1), ('liquidation', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(nouns)\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['report', 'court', 'year', 'liquidator', 'fee', 'liquidation']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 4\n",
    "***\n",
    "Using the method `.Dictionary()` inside the module `corpora` to create a unique token for every word and also print out the tokens assigned respectively using the `.token2id` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(171 unique tokens: ['2', '24', '5', '65', 'bcci']...)\n",
      "{'2': 0, '24': 1, '5': 2, '65': 3, 'bcci': 4, 'billion': 5, 'claim': 6, 'collapsed': 7, 'creditor': 8, 'equal': 9, 'five': 10, 'fraud': 11, 'liquidator': 12, 'monday': 13, 'payment': 14, 'percent': 15, 'receive': 16, 'ridden': 17, 'said': 18, 'spokesman': 19, 'struggle': 20, 'tuesday': 21, 'year': 22, '12': 23, '1972': 24, '1991': 25, 'bank': 26, 'central': 27, 'closed': 28, 'commerce': 29, 'conclusion': 30, 'credit': 31, 'debt': 32, 'early': 33, 'evidence': 34, 'founded': 35, 'international': 36, 'laundering': 37, 'leading': 38, 'litigation': 39, 'massive': 40, 'money': 41, 'reaching': 42, 'show': 43, 'sign': 44, 'tangled': 45, 'unearthed': 46, 'web': 47, '71': 48, 'asset': 49, 'collapse': 50, 'country': 51, 'operation': 52, 'time': 53, '10': 54, '16': 55, 'admitted': 56, 'deloitte': 57, 'made': 58, 'month': 59, 'next': 60, 'reportedly': 61, 'total': 62, 'touche': 63, '0': 64, '1': 65, '250': 66, '4': 67, 'abu': 68, 'amount': 69, 'around': 70, 'course': 71, 'dhabi': 72, 'due': 73, 'earlier': 74, 'following': 75, 'fund': 76, 'government': 77, 'gross': 78, 'includes': 79, 'majority': 80, 'million': 81, 'paid': 82, 'pay': 83, 'reached': 84, 'recovered': 85, 'settlement': 86, 'shareholder': 87, 'stand': 88, '500': 89, 'addition': 90, 'authority': 91, 'dividend': 92, 'effort': 93, 'first': 94, 'paved': 95, 'recovery': 96, 'resulted': 97, 'state': 98, 'u': 99, 'united': 100, 'way': 101, '245': 102, 'alleged': 103, 'billionaire': 104, 'bin': 105, 'covering': 106, 'involved': 107, 'khalid': 108, 'mahfouz': 109, 'saudi': 110, 'scandal': 111, 'sheikh': 112, '1995': 113, 'admitting': 114, 'agreed': 115, 'court': 116, 'dropped': 117, 'lawsuit': 118, 'liability': 119, 'luxembourg': 120, 'return': 121, 'without': 122, 'accountancy': 123, 'amp': 124, 'auditor': 125, 'based': 126, 'england': 127, 'ernst': 128, 'firm': 129, 'institut': 130, 'luxembourgeois': 131, 'luxembourgh': 132, 'merged': 133, 'monetaire': 134, 'outstanding': 135, 'part': 136, 'price': 137, 'still': 138, 'waterhouse': 139, 'whinney': 140, 'young': 141, 'counter': 142, 'dollar': 143, 'making': 144, 'multi': 145, 'also': 146, 'attempt': 147, 'law': 148, 'pending': 149, 'recover': 150, 'suit': 151, 'world': 152, 'arab': 153, 'biggest': 154, 'britain': 155, 'emirate': 156, 'group': 157, 'two': 158, 'uae': 159, '200': 160, 'deloite': 161, 'english': 162, 'fee': 163, '75': 164, 'ammounted': 165, 'far': 166, 'high': 167, 'legal': 168, 'liquidation': 169, 'report': 170}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 5\n",
    "***\n",
    "Now convert the dictionary into a bag of words list using the `.doc2bow()` method in `dictionary` and store it in a variable **corpus** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1)]\n",
      "[(5, 1), (7, 1), (11, 1), (23, 1), (24, 1), (25, 1), (26, 2), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1)]\n",
      "[(1, 1), (4, 1), (5, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1)]\n",
      "[(2, 1), (5, 1), (6, 1), (12, 1), (14, 1), (15, 1), (18, 1), (23, 1), (54, 2), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1)]\n",
      "[(2, 1), (4, 1), (5, 2), (12, 1), (22, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1)]\n",
      "[(14, 1), (81, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1)]\n",
      "[(4, 1), (12, 1), (81, 1), (82, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1)]\n",
      "[(83, 1), (86, 1), (109, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1)]\n",
      "[(4, 1), (6, 1), (12, 1), (26, 2), (36, 1), (52, 1), (123, 1), (124, 2), (125, 1), (126, 1), (127, 1), (128, 2), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1)]\n",
      "[(5, 1), (6, 1), (18, 1), (68, 1), (72, 1), (137, 1), (139, 1), (142, 1), (143, 1), (144, 1), (145, 1)]\n",
      "[(69, 1), (70, 1), (146, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 1)]\n",
      "[(4, 1), (8, 1), (100, 1), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (158, 1), (159, 1)]\n",
      "[(4, 1), (5, 1), (12, 1), (40, 1), (63, 1), (65, 1), (81, 1), (82, 1), (85, 1), (124, 1), (160, 1), (161, 1), (162, 1), (163, 1)]\n",
      "[(12, 1), (18, 1), (22, 1), (74, 1), (81, 1), (116, 1), (163, 1), (164, 1), (165, 1), (166, 1), (167, 1), (168, 1), (169, 1), (170, 1)]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in Text]\n",
    "for line in corpus :\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 6\n",
    "***\n",
    "Create an LDA model with number of topics as 5 of your choice and your choice of total passes. Now print out the top 5 topics and also the top 3 words in every topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LdaModel(num_terms=171, num_topics=5, decay=0.5, chunksize=2000)\n"
     ]
    }
   ],
   "source": [
    "ldamodel = models.ldamodel.LdaModel(corpus, num_topics=5, id2word = dictionary, passes=20)\n",
    "\n",
    "print(ldamodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.042*\"billion\" + 0.022*\"bcci\" + 0.022*\"said\"')\n",
      "(1, '0.025*\"bank\" + 0.014*\"united\" + 0.014*\"12\"')\n",
      "(2, '0.035*\"million\" + 0.035*\"liquidator\" + 0.019*\"court\"')\n",
      "(3, '0.028*\"bcci\" + 0.019*\"claim\" + 0.019*\"operation\"')\n",
      "(4, '0.025*\"touche\" + 0.025*\"bcci\" + 0.025*\"million\"')\n"
     ]
    }
   ],
   "source": [
    "for topic in ldamodel.print_topics(num_topics=5, num_words=3):\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisaurabh04/anaconda3/lib/python3.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el151201123467533283528124601\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el151201123467533283528124601_data = {\"mdsDat\": {\"x\": [0.07715906993416854, 0.054917134824233924, -0.14048980766239605, 0.009789799685940065, -0.001376196781946609], \"y\": [-0.10421873861568212, 0.09032982436737984, -0.019569059928614404, 0.03381311196355226, -0.00035513778663549947], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [32.06608963012695, 26.992767333984375, 22.0063533782959, 12.397101402282715, 6.537686347961426]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Freq\": [3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 5.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.4957648515701294, 1.4957443475723267, 1.4957226514816284, 1.4957340955734253, 0.8158711791038513, 0.8158712387084961, 0.8158711791038513, 0.8158712387084961, 0.8158711791038513, 0.8158711791038513, 0.8158711791038513, 0.8158710598945618, 0.815871000289917, 0.8158671855926514, 0.8158669471740723, 0.8158668875694275, 0.8158667683601379, 0.8158668279647827, 0.8158668279647827, 0.8158668279647827, 0.8158648610115051, 0.8158648610115051, 0.8158647418022156, 0.815864622592926, 0.8158644437789917, 0.8158623576164246, 0.8158605694770813, 0.8158587217330933, 0.8158584237098694, 0.8158582448959351, 2.1752610206604004, 1.4956529140472412, 1.495806097984314, 1.4952565431594849, 1.4941178560256958, 0.8160011172294617, 0.8159897327423096, 1.4365692138671875, 1.4365588426589966, 0.7836026549339294, 0.7836025953292847, 0.7836025953292847, 0.7836026549339294, 0.7836026549339294, 0.7836025953292847, 0.7836025953292847, 0.7836025953292847, 0.7836026549339294, 0.7836024761199951, 0.7835956811904907, 0.783595621585846, 0.7835955619812012, 0.7835954427719116, 0.7835627198219299, 0.783562183380127, 0.7835593819618225, 0.78355872631073, 0.7835586071014404, 0.7835571765899658, 0.7835559844970703, 0.7835551500320435, 0.7835533022880554, 0.7835521697998047, 0.7835524678230286, 0.7835521697998047, 0.7835420370101929, 0.7835304737091064, 1.4367610216140747, 2.7445685863494873, 1.4369714260101318, 1.4370046854019165, 1.4365936517715454, 1.4367479085922241, 1.4371733665466309, 0.7839359641075134, 0.7838689684867859, 0.7837715744972229, 0.7837681174278259, 0.7837627530097961, 0.7837429642677307, 0.783724308013916, 0.783691942691803, 0.7268346548080444, 0.7268346548080444, 0.7268346548080444, 0.7268346548080444, 0.7268345952033997, 0.7268345952033997, 0.7268345355987549, 0.7268345355987549, 0.7268345355987549, 0.7268345355987549, 0.7268345355987549, 0.7268345355987549, 0.7268295288085938, 0.7268295288085938, 0.7268293499946594, 0.7268293499946594, 0.7268293499946594, 0.7268293499946594, 0.7268292307853699, 0.7268147468566895, 0.7268115282058716, 0.7268110513687134, 0.7268092036247253, 0.7268048524856567, 0.7268049716949463, 0.7268039584159851, 0.7268038988113403, 0.7268027663230896, 0.7268022298812866, 0.7268013954162598, 1.3326091766357422, 0.727091372013092, 0.7269213199615479, 0.7268641591072083, 0.7268622517585754, 0.7268571257591248, 0.7268348932266235, 0.5648936629295349, 0.5648936629295349, 0.5648936629295349, 0.5648936629295349, 0.5648936033248901, 0.5648936033248901, 0.5648936033248901, 0.5648517608642578, 0.5648499727249146, 0.5648419260978699, 0.5648414492607117, 0.5648407936096191, 0.5648386478424072, 0.5648373365402222, 0.564836323261261, 0.5648307204246521, 0.5648216605186462, 0.5648019909858704, 0.5649394989013672, 1.0363800525665283, 0.565146803855896, 0.5650867819786072, 0.5648282766342163, 0.5647907853126526, 1.036049246788025, 0.5649934411048889, 0.5646233558654785, 0.09415154904127121, 0.09415148943662643, 0.09415154904127121, 0.09420833736658096, 0.09419985115528107, 0.09419866651296616, 0.39056888222694397, 0.39056825637817383, 0.3905620276927948, 0.39063408970832825, 0.3906109929084778, 0.39063313603401184, 0.3906245827674866, 0.3907318115234375, 0.3907029926776886, 0.3905579745769501, 0.390728235244751, 0.39052170515060425, 0.39073124527931213, 0.3906080722808838, 0.06515149772167206, 0.06514519453048706, 0.06514129787683487, 0.06514061242341995, 0.06513971835374832, 0.06513826549053192, 0.06513780355453491, 0.06513749063014984, 0.06513196974992752, 0.06513067334890366, 0.06510161608457565, 0.06510160863399506, 0.06510160118341446, 0.06510160118341446, 0.06510159373283386, 0.06510159373283386, 0.06510158628225327, 0.06514875590801239, 0.0651245191693306, 0.06512073427438736, 0.06511475890874863, 0.06511431932449341, 0.0651131272315979], \"Term\": [\"million\", \"liquidator\", \"amp\", \"paid\", \"fee\", \"touche\", \"massive\", \"1\", \"recovered\", \"bcci\", \"billion\", \"200\", \"english\", \"deloite\", \"year\", \"earlier\", \"court\", \"mahfouz\", \"liquidation\", \"high\", \"far\", \"75\", \"ammounted\", \"legal\", \"report\", \"alleged\", \"saudi\", \"involved\", \"billionaire\", \"scandal\", \"operation\", \"10\", \"ernst\", \"amp\", \"return\", \"without\", \"luxembourg\", \"dropped\", \"agreed\", \"admitting\", \"liability\", \"lawsuit\", \"1995\", \"britain\", \"two\", \"emirate\", \"arab\", \"group\", \"biggest\", \"uae\", \"71\", \"time\", \"collapse\", \"asset\", \"country\", \"deloitte\", \"next\", \"month\", \"16\", \"total\", \"bcci\", \"bank\", \"claim\", \"liquidator\", \"billion\", \"price\", \"waterhouse\", \"abu\", \"dhabi\", \"spokesman\", \"equal\", \"five\", \"receive\", \"ridden\", \"tuesday\", \"struggle\", \"2\", \"65\", \"monday\", \"making\", \"dollar\", \"counter\", \"multi\", \"fund\", \"includes\", \"course\", \"4\", \"gross\", \"reached\", \"250\", \"shareholder\", \"following\", \"0\", \"government\", \"due\", \"majority\", \"stand\", \"year\", \"billion\", \"5\", \"said\", \"claim\", \"liquidator\", \"bcci\", \"24\", \"creditor\", \"around\", \"settlement\", \"pay\", \"amount\", \"payment\", \"percent\", \"dividend\", \"u\", \"effort\", \"resulted\", \"paved\", \"500\", \"state\", \"authority\", \"first\", \"addition\", \"way\", \"recovery\", \"law\", \"attempt\", \"pending\", \"recover\", \"suit\", \"world\", \"also\", \"early\", \"money\", \"leading\", \"tangled\", \"litigation\", \"sign\", \"founded\", \"closed\", \"central\", \"commerce\", \"debt\", \"bank\", \"united\", \"12\", \"payment\", \"fraud\", \"collapsed\", \"international\", \"liquidation\", \"high\", \"75\", \"far\", \"ammounted\", \"report\", \"legal\", \"alleged\", \"saudi\", \"involved\", \"billionaire\", \"scandal\", \"bin\", \"khalid\", \"sheikh\", \"245\", \"covering\", \"fee\", \"earlier\", \"million\", \"court\", \"mahfouz\", \"paid\", \"year\", \"liquidator\", \"said\", \"bcci\", \"200\", \"english\", \"deloite\", \"amount\", \"billion\", \"stand\", \"200\", \"english\", \"deloite\", \"fee\", \"massive\", \"1\", \"recovered\", \"touche\", \"paid\", \"amp\", \"million\", \"liquidator\", \"bcci\", \"billion\", \"covering\", \"245\", \"sheikh\", \"khalid\", \"bin\", \"scandal\", \"billionaire\", \"involved\", \"saudi\", \"alleged\", \"ammounted\", \"75\", \"report\", \"legal\", \"high\", \"far\", \"liquidation\", \"mahfouz\", \"10\", \"payment\", \"5\", \"said\", \"percent\"], \"Total\": [3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 5.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.9067916870117188, 1.9067686796188354, 1.9067916870117188, 2.2323341369628906, 1.226876139640808, 1.226876139640808, 1.226876139640808, 1.226876139640808, 1.226876139640808, 1.2268760204315186, 1.226876139640808, 1.2268760204315186, 1.2268760204315186, 1.2268747091293335, 1.226874589920044, 1.2268747091293335, 1.2268747091293335, 1.2268747091293335, 1.2268747091293335, 1.2268747091293335, 1.2268739938735962, 1.2268741130828857, 1.2268739938735962, 1.2268738746643066, 1.2268738746643066, 1.2268707752227783, 1.226869821548462, 1.2268688678741455, 1.2268686294555664, 1.2268686294555664, 4.688936233520508, 3.1181938648223877, 3.2128078937530518, 4.479721546173096, 5.449984550476074, 1.879884958267212, 1.8798844814300537, 1.8529847860336304, 1.8529818058013916, 1.1999825239181519, 1.1999825239181519, 1.1999825239181519, 1.1999825239181519, 1.1999825239181519, 1.1999826431274414, 1.1999826431274414, 1.1999826431274414, 1.1999826431274414, 1.1999825239181519, 1.19998037815094, 1.19998037815094, 1.19998037815094, 1.19998037815094, 1.1999706029891968, 1.199970006942749, 1.1999696493148804, 1.1999688148498535, 1.1999690532684326, 1.1999680995941162, 1.1999683380126953, 1.1999680995941162, 1.1999675035476685, 1.1999669075012207, 1.199967622756958, 1.1999672651290894, 1.1999644041061401, 1.199960708618164, 2.3237857818603516, 5.449984550476074, 2.5328545570373535, 3.0035762786865234, 3.2128078937530518, 4.479721546173096, 4.688936233520508, 1.8798643350601196, 1.879867672920227, 1.805680751800537, 1.8798577785491943, 1.8798563480377197, 1.8056730031967163, 2.4855542182922363, 1.879866600036621, 1.1526774168014526, 1.1526774168014526, 1.1526774168014526, 1.1526775360107422, 1.1526774168014526, 1.1526774168014526, 1.1526774168014526, 1.1526774168014526, 1.1526774168014526, 1.1526774168014526, 1.1526775360107422, 1.1526775360107422, 1.1526762247085571, 1.1526762247085571, 1.1526762247085571, 1.1526762247085571, 1.1526762247085571, 1.1526763439178467, 1.1526761054992676, 1.1526812314987183, 1.152681589126587, 1.152681589126587, 1.1526819467544556, 1.1526824235916138, 1.1526825428009033, 1.1526825428009033, 1.1526825428009033, 1.1526827812194824, 1.1526827812194824, 1.152682900428772, 3.1181938648223877, 1.8325425386428833, 1.8325605392456055, 2.4855542182922363, 1.8056820631027222, 1.8056827783584595, 1.8325775861740112, 1.0177265405654907, 1.0177265405654907, 1.0177265405654907, 1.0177266597747803, 1.0177265405654907, 1.0177266597747803, 1.0177266597747803, 1.0177136659622192, 1.0177130699157715, 1.0177104473114014, 1.0177104473114014, 1.0177100896835327, 1.017709493637085, 1.0177091360092163, 1.0177087783813477, 1.017707109451294, 1.0177043676376343, 1.3432284593582153, 1.6707111597061157, 3.0723421573638916, 1.6975127458572388, 1.6974903345108032, 1.9961544275283813, 2.3237857818603516, 4.479721546173096, 3.0035762786865234, 4.688936233520508, 0.8725091814994812, 0.8725098967552185, 0.8725160360336304, 1.8056730031967163, 5.449984550476074, 1.199960708618164, 0.8725091814994812, 0.8725098967552185, 0.8725160360336304, 1.3432284593582153, 1.4781758785247803, 1.5254348516464233, 1.525444507598877, 1.5522316694259644, 1.9961544275283813, 2.2323341369628906, 3.0723421573638916, 4.479721546173096, 4.688936233520508, 5.449984550476074, 1.0177043676376343, 1.017707109451294, 1.0177087783813477, 1.0177091360092163, 1.017709493637085, 1.0177100896835327, 1.0177104473114014, 1.0177104473114014, 1.0177130699157715, 1.0177136659622192, 1.0177265405654907, 1.0177265405654907, 1.0177266597747803, 1.0177266597747803, 1.0177265405654907, 1.0177266597747803, 1.0177265405654907, 1.6974903345108032, 1.9067686796188354, 2.4855542182922363, 2.5328545570373535, 3.0035762786865234, 1.879866600036621], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.894599974155426, 0.894599974155426, 0.894599974155426, 0.7368999719619751, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.7293999791145325, 0.3693000078201294, 0.4027000069618225, 0.37290000915527344, 0.04010000079870224, -0.156700000166893, 0.3027999997138977, 0.3027999997138977, 1.0550999641418457, 1.0550999641418457, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.883400022983551, 0.8288000226020813, 0.6236000061035156, 0.7427999973297119, 0.5723999738693237, 0.5047000050544739, 0.17239999771118164, 0.12710000574588776, 0.4350000023841858, 0.4348999857902527, 0.4749999940395355, 0.43479999899864197, 0.43479999899864197, 0.4749999940395355, 0.15539999306201935, 0.43470001220703125, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0527000427246094, 1.0526000261306763, 1.0526000261306763, 1.0526000261306763, 1.0526000261306763, 1.0526000261306763, 1.0526000261306763, 1.0526000261306763, 0.6636999845504761, 0.5893999934196472, 0.5892000198364258, 0.2842999994754791, 0.6039000153541565, 0.6039000153541565, 0.5891000032424927, 1.4989999532699585, 1.4989999532699585, 1.4989999532699585, 1.4989999532699585, 1.4989999532699585, 1.4989999532699585, 1.4989999532699585, 1.4989999532699585, 1.4989999532699585, 1.498900055885315, 1.498900055885315, 1.498900055885315, 1.498900055885315, 1.498900055885315, 1.498900055885315, 1.498900055885315, 1.498900055885315, 1.2214000225067139, 1.0033999681472778, 1.0010000467300415, 0.9879000186920166, 0.9878000020980835, 0.8252999782562256, 0.6732000112533569, 0.6236000061035156, 0.4169999957084656, -0.029100000858306885, -0.1387999951839447, -0.1387999951839447, -0.1387999951839447, -0.8654999732971191, -1.9701999425888062, -0.4569000005722046, 1.923799991607666, 1.923799991607666, 1.923799991607666, 1.4924999475479126, 1.3967000246047974, 1.3653000593185425, 1.3653000593185425, 1.3481999635696411, 1.09660005569458, 0.9843999743461609, 0.6654000282287598, 0.28780001401901245, 0.2425999939441681, 0.09189999848604202, -0.020999999716877937, -0.0210999995470047, -0.021199999377131462, -0.021199999377131462, -0.021199999377131462, -0.021199999377131462, -0.021199999377131462, -0.021199999377131462, -0.021299999207258224, -0.021299999207258224, -0.021800000220537186, -0.021800000220537186, -0.021800000220537186, -0.021800000220537186, -0.021800000220537186, -0.021800000220537186, -0.021800000220537186, -0.5325999855995178, -0.6492999792098999, -0.9143999814987183, -0.9333999752998352, -1.1038000583648682, -0.635200023651123], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.9405999183654785, -3.9405999183654785, -3.940700054168701, -3.940700054168701, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -4.546800136566162, -3.5660998821258545, -3.940700054168701, -3.9405999183654785, -3.940999984741211, -3.941699981689453, -4.546599864959717, -4.546599864959717, -3.808799982070923, -3.808799982070923, -4.414899826049805, -4.414899826049805, -4.414899826049805, -4.414899826049805, -4.414899826049805, -4.414899826049805, -4.414899826049805, -4.414899826049805, -4.414899826049805, -4.414899826049805, -4.414899826049805, -4.414899826049805, -4.414899826049805, -4.414899826049805, -4.414899826049805, -4.414899826049805, -4.414899826049805, -4.414899826049805, -4.414899826049805, -4.414899826049805, -4.414999961853027, -4.414999961853027, -4.414999961853027, -4.414999961853027, -4.414999961853027, -4.414999961853027, -4.414999961853027, -4.414999961853027, -3.8085999488830566, -3.161400079727173, -3.808500051498413, -3.808500051498413, -3.808799982070923, -3.8087000846862793, -3.8083999156951904, -4.4145002365112305, -4.414599895477295, -4.414700031280518, -4.414700031280518, -4.414700031280518, -4.414700031280518, -4.414700031280518, -4.41480016708374, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -4.285900115966797, -3.6796998977661133, -4.2855000495910645, -4.285699844360352, -4.285799980163574, -4.285799980163574, -4.285799980163574, -4.285900115966797, -3.9639999866485596, -3.9639999866485596, -3.9639999866485596, -3.9639999866485596, -3.9639999866485596, -3.9639999866485596, -3.9639999866485596, -3.964099884033203, -3.964099884033203, -3.964099884033203, -3.964099884033203, -3.964099884033203, -3.964099884033203, -3.964099884033203, -3.964200019836426, -3.964200019836426, -3.964200019836426, -3.964200019836426, -3.9639999866485596, -3.3571999073028564, -3.963599920272827, -3.96370005607605, -3.964200019836426, -3.964200019836426, -3.3575000762939453, -3.963900089263916, -3.9644999504089355, -5.755799770355225, -5.755799770355225, -5.755799770355225, -5.755199909210205, -5.755300045013428, -5.755300045013428, -3.69320011138916, -3.69320011138916, -3.69320011138916, -3.693000078201294, -3.6930999755859375, -3.693000078201294, -3.6930999755859375, -3.6928000450134277, -3.6928999423980713, -3.69320011138916, -3.6928000450134277, -3.6933000087738037, -3.6928000450134277, -3.6930999755859375, -5.484099864959717, -5.4842000007629395, -5.4842000007629395, -5.484300136566162, -5.484300136566162, -5.484300136566162, -5.484300136566162, -5.484300136566162, -5.484399795532227, -5.484399795532227, -5.484899997711182, -5.484899997711182, -5.484899997711182, -5.484899997711182, -5.484899997711182, -5.484899997711182, -5.484899997711182, -5.484099864959717, -5.484499931335449, -5.484600067138672, -5.4847002029418945, -5.4847002029418945, -5.4847002029418945]}, \"token.table\": {\"Topic\": [2, 2, 1, 1, 3, 1, 1, 2, 1, 2, 4, 2, 2, 1, 2, 3, 2, 1, 4, 2, 3, 1, 1, 4, 3, 4, 2, 3, 1, 1, 2, 3, 1, 3, 3, 1, 3, 1, 2, 4, 1, 1, 2, 3, 4, 4, 1, 3, 1, 2, 3, 1, 2, 3, 3, 2, 1, 2, 1, 4, 4, 1, 2, 3, 1, 2, 3, 2, 1, 2, 2, 4, 3, 3, 1, 2, 1, 4, 4, 3, 2, 2, 3, 2, 3, 2, 2, 2, 1, 4, 2, 1, 3, 4, 4, 3, 1, 3, 4, 1, 4, 1, 2, 4, 3, 1, 1, 4, 2, 2, 3, 2, 3, 4, 2, 3, 1, 2, 1, 1, 2, 4, 3, 1, 2, 1, 2, 3, 3, 1, 2, 1, 2, 2, 2, 3, 2, 3, 4, 3, 1, 2, 1, 2, 4, 4, 4, 1, 2, 2, 4, 3, 2, 2, 3, 2, 3, 3, 1, 1, 1, 2, 1, 3, 1, 1, 3, 1, 2, 3, 1, 3, 2, 4], \"Freq\": [0.8333563208580017, 0.6555507779121399, 0.5244474411010742, 0.5456845760345459, 0.5456845760345459, 0.8150832056999207, 0.8150782585144043, 0.8333454132080078, 0.5319532752037048, 0.5319532752037048, 0.98260098695755, 0.8333553075790405, 0.8333550095558167, 0.3948114514350891, 0.3948114514350891, 0.8675454258918762, 0.8333454132080078, 0.8150796294212341, 0.9825822114944458, 0.5396698117256165, 0.8675454258918762, 0.8150782585144043, 0.8150781989097595, 0.9825946688652039, 0.8675463795661926, 0.9825822114944458, 0.5538101196289062, 0.5538101196289062, 0.44796159863471985, 0.8150791525840759, 0.5538077354431152, 0.5538077354431152, 0.8150796890258789, 0.8675463199615479, 0.8675454258918762, 0.32069846987724304, 0.32069846987724304, 0.426535964012146, 0.213267982006073, 0.213267982006073, 0.8150791525840759, 0.18348675966262817, 0.5504602789878845, 0.18348675966262817, 0.9825977683067322, 0.9825986623764038, 0.8150791525840759, 0.8675413727760315, 0.31125420331954956, 0.31125420331954956, 0.8675415515899658, 0.8150796294212341, 0.5538071393966675, 0.5538071393966675, 0.8675413727760315, 0.833346962928772, 0.8150796890258789, 0.8333544135093689, 0.5890972018241882, 0.5890972018241882, 0.9826036095619202, 0.5319523215293884, 0.5319523215293884, 0.8675412535667419, 0.815081775188446, 0.5396707057952881, 0.8675454258918762, 0.833346962928772, 0.8150781989097595, 0.8333560824394226, 0.5985475182533264, 0.5985475182533264, 0.867542564868927, 0.8675454258918762, 0.8150791525840759, 0.8333454728126526, 0.524441123008728, 0.9825820922851562, 0.7444750070571899, 0.8675454258918762, 0.8333454728126526, 0.8333559036254883, 0.8675415515899658, 0.5538073778152466, 0.5538073778152466, 0.8333537578582764, 0.8333558440208435, 0.8333548307418823, 0.8150791525840759, 0.9825822114944458, 0.8333541750907898, 0.54567950963974, 0.54567950963974, 0.9825977683067322, 0.9825990200042725, 0.8675463199615479, 0.8150782585144043, 0.8675422668457031, 0.9825820922851562, 0.8150781989097595, 0.9825822114944458, 0.22322815656661987, 0.22322815656661987, 0.22322815656661987, 0.8675416111946106, 0.8150781989097595, 0.589104950428009, 0.589104950428009, 0.8333580493927002, 0.833346962928772, 0.6765094995498657, 0.32548457384109497, 0.32548457384109497, 0.32548457384109497, 0.8333454728126526, 0.8675422668457031, 0.8150830268859863, 0.833346962928772, 0.8150824308395386, 0.524441123008728, 0.5009632706642151, 0.5009632706642151, 0.8675454258918762, 0.5319555401802063, 0.5319555401802063, 0.40232476592063904, 0.40232476592063904, 0.40232476592063904, 0.8675463199615479, 0.5319526195526123, 0.5319526195526123, 0.5319474339485168, 0.5319474339485168, 0.8333554863929749, 0.8333454728126526, 0.8675463199615479, 0.6555466055870056, 0.8675453066825867, 0.9825820922851562, 0.8675453066825867, 0.8150781989097595, 0.8333454728126526, 0.33293643593788147, 0.33293643593788147, 0.33293643593788147, 0.9825952053070068, 0.9825981259346008, 0.5319551229476929, 0.5319551229476929, 0.8333554863929749, 0.9825993776321411, 0.8675415515899658, 0.8333454728126526, 0.8333606123924255, 0.8675454258918762, 0.8333454132080078, 0.8675463199615479, 0.867542028427124, 0.8150795698165894, 0.8150832056999207, 0.6442337036132812, 0.8333454132080078, 0.8150792121887207, 0.8675454258918762, 0.8150791525840759, 0.5456899404525757, 0.5456899404525757, 0.5319475531578064, 0.5319475531578064, 0.8675453066825867, 0.8150781989097595, 0.8675462007522583, 0.4303322732448578, 0.4303322732448578], \"Term\": [\"0\", \"1\", \"10\", \"12\", \"12\", \"16\", \"1995\", \"2\", \"24\", \"24\", \"245\", \"250\", \"4\", \"5\", \"5\", \"500\", \"65\", \"71\", \"75\", \"abu\", \"addition\", \"admitting\", \"agreed\", \"alleged\", \"also\", \"ammounted\", \"amount\", \"amount\", \"amp\", \"arab\", \"around\", \"around\", \"asset\", \"attempt\", \"authority\", \"bank\", \"bank\", \"bcci\", \"bcci\", \"bcci\", \"biggest\", \"billion\", \"billion\", \"billion\", \"billionaire\", \"bin\", \"britain\", \"central\", \"claim\", \"claim\", \"closed\", \"collapse\", \"collapsed\", \"collapsed\", \"commerce\", \"counter\", \"country\", \"course\", \"court\", \"court\", \"covering\", \"creditor\", \"creditor\", \"debt\", \"deloitte\", \"dhabi\", \"dividend\", \"dollar\", \"dropped\", \"due\", \"earlier\", \"earlier\", \"early\", \"effort\", \"emirate\", \"equal\", \"ernst\", \"far\", \"fee\", \"first\", \"five\", \"following\", \"founded\", \"fraud\", \"fraud\", \"fund\", \"government\", \"gross\", \"group\", \"high\", \"includes\", \"international\", \"international\", \"involved\", \"khalid\", \"law\", \"lawsuit\", \"leading\", \"legal\", \"liability\", \"liquidation\", \"liquidator\", \"liquidator\", \"liquidator\", \"litigation\", \"luxembourg\", \"mahfouz\", \"mahfouz\", \"majority\", \"making\", \"massive\", \"million\", \"million\", \"million\", \"monday\", \"money\", \"month\", \"multi\", \"next\", \"operation\", \"paid\", \"paid\", \"paved\", \"pay\", \"pay\", \"payment\", \"payment\", \"payment\", \"pending\", \"percent\", \"percent\", \"price\", \"price\", \"reached\", \"receive\", \"recover\", \"recovered\", \"recovery\", \"report\", \"resulted\", \"return\", \"ridden\", \"said\", \"said\", \"said\", \"saudi\", \"scandal\", \"settlement\", \"settlement\", \"shareholder\", \"sheikh\", \"sign\", \"spokesman\", \"stand\", \"state\", \"struggle\", \"suit\", \"tangled\", \"time\", \"total\", \"touche\", \"tuesday\", \"two\", \"u\", \"uae\", \"united\", \"united\", \"waterhouse\", \"waterhouse\", \"way\", \"without\", \"world\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 1, 2, 3, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el151201123467533283528124601\", ldavis_el151201123467533283528124601_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el151201123467533283528124601\", ldavis_el151201123467533283528124601_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el151201123467533283528124601\", ldavis_el151201123467533283528124601_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "3      0.077159 -0.104219       1        1  32.066090\n",
       "0      0.054917  0.090330       2        1  26.992767\n",
       "1     -0.140490 -0.019569       3        1  22.006353\n",
       "2      0.009790  0.033813       4        1  12.397101\n",
       "4     -0.001376 -0.000355       5        1   6.537686, topic_info=    Category      Freq         Term     Total  loglift  logprob\n",
       "81   Default  3.000000      million  3.000000  30.0000  30.0000\n",
       "12   Default  4.000000   liquidator  4.000000  29.0000  29.0000\n",
       "124  Default  2.000000          amp  2.000000  28.0000  28.0000\n",
       "82   Default  1.000000         paid  1.000000  27.0000  27.0000\n",
       "163  Default  1.000000          fee  1.000000  26.0000  26.0000\n",
       "63   Default  1.000000       touche  1.000000  25.0000  25.0000\n",
       "40   Default  1.000000      massive  1.000000  24.0000  24.0000\n",
       "65   Default  1.000000            1  1.000000  23.0000  23.0000\n",
       "85   Default  1.000000    recovered  1.000000  22.0000  22.0000\n",
       "4    Default  4.000000         bcci  4.000000  21.0000  21.0000\n",
       "5    Default  5.000000      billion  5.000000  20.0000  20.0000\n",
       "160  Default  0.000000          200  0.000000  19.0000  19.0000\n",
       "162  Default  0.000000      english  0.000000  18.0000  18.0000\n",
       "161  Default  0.000000      deloite  0.000000  17.0000  17.0000\n",
       "22   Default  2.000000         year  2.000000  16.0000  16.0000\n",
       "74   Default  1.000000      earlier  1.000000  15.0000  15.0000\n",
       "116  Default  1.000000        court  1.000000  14.0000  14.0000\n",
       "109  Default  1.000000      mahfouz  1.000000  13.0000  13.0000\n",
       "169  Default  1.000000  liquidation  1.000000  12.0000  12.0000\n",
       "167  Default  1.000000         high  1.000000  11.0000  11.0000\n",
       "166  Default  1.000000          far  1.000000  10.0000  10.0000\n",
       "164  Default  1.000000           75  1.000000   9.0000   9.0000\n",
       "165  Default  1.000000    ammounted  1.000000   8.0000   8.0000\n",
       "168  Default  1.000000        legal  1.000000   7.0000   7.0000\n",
       "170  Default  1.000000       report  1.000000   6.0000   6.0000\n",
       "103  Default  1.000000      alleged  1.000000   5.0000   5.0000\n",
       "110  Default  1.000000        saudi  1.000000   4.0000   4.0000\n",
       "107  Default  1.000000     involved  1.000000   3.0000   3.0000\n",
       "104  Default  1.000000  billionaire  1.000000   2.0000   2.0000\n",
       "111  Default  1.000000      scandal  1.000000   1.0000   1.0000\n",
       "..       ...       ...          ...       ...      ...      ...\n",
       "63    Topic5  0.390732       touche  1.552232   1.3482  -3.6928\n",
       "82    Topic5  0.390703         paid  1.996154   1.0966  -3.6929\n",
       "124   Topic5  0.390558          amp  2.232334   0.9844  -3.6932\n",
       "81    Topic5  0.390728      million  3.072342   0.6654  -3.6928\n",
       "12    Topic5  0.390522   liquidator  4.479722   0.2878  -3.6933\n",
       "4     Topic5  0.390731         bcci  4.688936   0.2426  -3.6928\n",
       "5     Topic5  0.390608      billion  5.449985   0.0919  -3.6931\n",
       "106   Topic5  0.065151     covering  1.017704  -0.0210  -5.4841\n",
       "102   Topic5  0.065145          245  1.017707  -0.0211  -5.4842\n",
       "112   Topic5  0.065141       sheikh  1.017709  -0.0212  -5.4842\n",
       "108   Topic5  0.065141       khalid  1.017709  -0.0212  -5.4843\n",
       "105   Topic5  0.065140          bin  1.017709  -0.0212  -5.4843\n",
       "111   Topic5  0.065138      scandal  1.017710  -0.0212  -5.4843\n",
       "104   Topic5  0.065138  billionaire  1.017710  -0.0212  -5.4843\n",
       "107   Topic5  0.065137     involved  1.017710  -0.0212  -5.4843\n",
       "110   Topic5  0.065132        saudi  1.017713  -0.0213  -5.4844\n",
       "103   Topic5  0.065131      alleged  1.017714  -0.0213  -5.4844\n",
       "165   Topic5  0.065102    ammounted  1.017727  -0.0218  -5.4849\n",
       "164   Topic5  0.065102           75  1.017727  -0.0218  -5.4849\n",
       "170   Topic5  0.065102       report  1.017727  -0.0218  -5.4849\n",
       "168   Topic5  0.065102        legal  1.017727  -0.0218  -5.4849\n",
       "167   Topic5  0.065102         high  1.017727  -0.0218  -5.4849\n",
       "166   Topic5  0.065102          far  1.017727  -0.0218  -5.4849\n",
       "169   Topic5  0.065102  liquidation  1.017727  -0.0218  -5.4849\n",
       "109   Topic5  0.065149      mahfouz  1.697490  -0.5326  -5.4841\n",
       "54    Topic5  0.065125           10  1.906769  -0.6493  -5.4845\n",
       "14    Topic5  0.065121      payment  2.485554  -0.9144  -5.4846\n",
       "2     Topic5  0.065115            5  2.532855  -0.9334  -5.4847\n",
       "18    Topic5  0.065114         said  3.003576  -1.1038  -5.4847\n",
       "15    Topic5  0.065113      percent  1.879867  -0.6352  -5.4847\n",
       "\n",
       "[219 rows x 6 columns], token_table=      Topic      Freq         Term\n",
       "term                              \n",
       "64        2  0.833356            0\n",
       "65        2  0.655551            1\n",
       "54        1  0.524447           10\n",
       "23        1  0.545685           12\n",
       "23        3  0.545685           12\n",
       "55        1  0.815083           16\n",
       "113       1  0.815078         1995\n",
       "0         2  0.833345            2\n",
       "1         1  0.531953           24\n",
       "1         2  0.531953           24\n",
       "102       4  0.982601          245\n",
       "66        2  0.833355          250\n",
       "67        2  0.833355            4\n",
       "2         1  0.394811            5\n",
       "2         2  0.394811            5\n",
       "89        3  0.867545          500\n",
       "3         2  0.833345           65\n",
       "48        1  0.815080           71\n",
       "164       4  0.982582           75\n",
       "68        2  0.539670          abu\n",
       "90        3  0.867545     addition\n",
       "114       1  0.815078    admitting\n",
       "115       1  0.815078       agreed\n",
       "103       4  0.982595      alleged\n",
       "146       3  0.867546         also\n",
       "165       4  0.982582    ammounted\n",
       "69        2  0.553810       amount\n",
       "69        3  0.553810       amount\n",
       "124       1  0.447962          amp\n",
       "153       1  0.815079         arab\n",
       "...     ...       ...          ...\n",
       "18        4  0.332936         said\n",
       "110       4  0.982595        saudi\n",
       "111       4  0.982598      scandal\n",
       "86        1  0.531955   settlement\n",
       "86        2  0.531955   settlement\n",
       "87        2  0.833355  shareholder\n",
       "112       4  0.982599       sheikh\n",
       "44        3  0.867542         sign\n",
       "19        2  0.833345    spokesman\n",
       "88        2  0.833361        stand\n",
       "98        3  0.867545        state\n",
       "20        2  0.833345     struggle\n",
       "151       3  0.867546         suit\n",
       "45        3  0.867542      tangled\n",
       "53        1  0.815080         time\n",
       "62        1  0.815083        total\n",
       "63        1  0.644234       touche\n",
       "21        2  0.833345      tuesday\n",
       "158       1  0.815079          two\n",
       "99        3  0.867545            u\n",
       "159       1  0.815079          uae\n",
       "100       1  0.545690       united\n",
       "100       3  0.545690       united\n",
       "139       1  0.531948   waterhouse\n",
       "139       2  0.531948   waterhouse\n",
       "101       3  0.867545          way\n",
       "122       1  0.815078      without\n",
       "152       3  0.867546        world\n",
       "22        2  0.430332         year\n",
       "22        4  0.430332         year\n",
       "\n",
       "[174 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 2, 3, 5])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis = pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/quiz.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "## Topic Modelling\n",
    "***\n",
    "\n",
    "Q1. What percentage of the total statements are correct with regards to Topic Modeling?\n",
    "```python\n",
    "1. It is a supervised learning technique\n",
    "2. LDA (Linear Discriminant Analysis) can be used to perform topic modeling\n",
    "3. Selection of number of topics in a model does not depend on the size of data\n",
    "4. Number of topic terms are directly proportional to size of the data\n",
    "A) 0\n",
    "B) 25\n",
    "C) 50\n",
    "D) 75\n",
    "E) 100\n",
    "\n",
    "\n",
    "\n",
    "LDA is unsupervised learning model, LDA is latent Dirichlet allocation, not Linear discriminant analysis. Selection of the number of topics is directly proportional to the size of the data, while number of topic terms is not directly proportional to the size of the data. Hence none of the statements are correct.\n",
    "```\n",
    "\n",
    "Q2. In Latent Dirichlet Allocation model for text classification purposes, what does alpha and beta hyperparameter represent-\n",
    "```python\n",
    "A) Alpha: number of topics within documents, beta: number of terms within topics False\n",
    "B) Alpha: density of terms generated within topics, beta: density of topics generated within terms False\n",
    "C) Alpha: number of topics within documents, beta: number of terms within topics False\n",
    "D) Alpha: density of topics generated within documents, beta: density of terms generated within topics True\n",
    "\n",
    "\n",
    "```\n",
    "Q3. Social Media platforms are the most intuitive form of text data. You are given a corpus of complete social media data of tweets. How can you create a model that suggests the hashtags?\n",
    "```python\n",
    "A) Perform Topic Models to obtain most significant words of the corpus\n",
    "B) Train a Bag of Ngrams model to capture top n-grams – words and their combinations\n",
    "C) Train a word2vector model to learn repeating contexts in the sentences\n",
    "D) All of these\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
